{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ac78307-c58c-4f51-9394-72a35b8dc8e0",
   "metadata": {},
   "source": [
    "PyTorch CNN ensemble\n",
    "---\n",
    "\n",
    "Equivalent to Keras ensemble in `fit_ensemble.ipynb`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a35e517-7fb4-466f-8c90-487b96bad961",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    " <strong>Note:</strong><br>This is currently under heavy development. Nothing is gonna work in here.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9918b7-6593-4b18-a223-605d525501ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Using {device} for inference')\n",
    "\n",
    "n_pixels = 224\n",
    "n_test = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c575f4ca-9a76-4c7f-9528-987a98d634f8",
   "metadata": {},
   "source": [
    "## Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3398881-bcc4-46b5-8699-6cb1f478826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [i for i in range(30) for j in range(12)] # creates 360 list items like so: [0, 0, 0, 0, ... 29, 29, 29, 29]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc824d1-e3b2-4fe8-9b31-507fd2c326e5",
   "metadata": {},
   "source": [
    "## Functions ...\n",
    "... from https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b97c899-da5c-4399-ac69-362eae2c303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    \"\"\"\n",
    "    The train_model function handles the training and validation of a given model.\n",
    "    As input, it takes a PyTorch model, a dictionary of dataloaders, a loss function,\n",
    "    an optimizer, a specified number of epochs to train and validate for,\n",
    "    and a boolean flag for when the model is an Inception model. The is_inception\n",
    "    flag is used to accomodate the Inception v3 model, as that architecture uses an\n",
    "    auxiliary output and the overall model loss respects both the auxiliary output and\n",
    "    the final output, as described here. The function trains for the specified number\n",
    "    of epochs and after each epoch runs a full validation step. It also keeps track of\n",
    "    the best performing model (in terms of validation accuracy), and at the end of training\n",
    "    returns the best performing model. \n",
    "    After each epoch, the training and validation accuracies are printed.\n",
    "    \"\"\"\n",
    "    \n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history\n",
    "\n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    \"\"\"\n",
    "    This helper function sets the .requires_grad attribute of the parameters in the model to False\n",
    "    when we are feature extracting. By default, when we load a pretrained model all of the\n",
    "    parameters have .requires_grad=True, which is fine if we are training from scratch or finetuning.\n",
    "    However, if we are feature extracting and only want to compute gradients for the newly initialized\n",
    "    layer then we want all of the other parameters to not require gradients.\n",
    "    This will make more sense later.\n",
    "    \"\"\"\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442c0755-2bd7-485a-a1da-886e58709894",
   "metadata": {},
   "source": [
    "## Prepare 360 Rocks data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdf7f63-9558-4a4b-874f-0a6e21fa3039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data directory. Here we assume the format of the directory conforms\n",
    "#   to the ImageFolder structure\n",
    "data_dir = \"../sanders_2018/360 Rocks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc5da93-c59b-43a5-bf79-0086dbc2d40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "print(\"Initializing Datasets and Dataloaders...\")\n",
    "\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "949a8363-e99a-4dac-95b0-cfd904ea8e4f",
   "metadata": {},
   "source": [
    "# load image files\n",
    "X = load_images(\"../sanders_2018/360 Rocks\", nPixels, lambda x: resnet50.preprocess_input(np.expand_dims(x, axis=0)).squeeze())\n",
    "\n",
    "# load labels\n",
    "mds_360 = np.loadtxt(\"../sanders_2018/mds_360.txt\")\n",
    "\n",
    "# split data: train vs test\n",
    "(X_train_, X_test, \n",
    " Y_train_, Y_test, \n",
    " categories_train_, categories_test) = train_test_split(X, \n",
    "                                                        mds_360, \n",
    "                                                        categories,\n",
    "                                                        test_size=nTest,\n",
    "                                                        stratify=categories, \n",
    "                                                        random_state=0)\n",
    "\n",
    "# split train set again: train vs validate\n",
    "(X_train, X_validate, \n",
    " Y_train, Y_validate) = train_test_split(X_train_, \n",
    "                                         Y_train_, \n",
    "                                         test_size=nTest,\n",
    "                                         stratify=categories_train_, \n",
    "                                         random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3f8eef-b65e-48c5-b32a-80f75ae68a9b",
   "metadata": {},
   "source": [
    "## Prepare 120 Rocks data\n",
    "\n",
    "no train, test, validate splits ...will be later used only for testing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec295123-1613-48a7-94ea-1ca6ff69df68",
   "metadata": {},
   "source": [
    "# load image files\n",
    "X_120 = load_images(\"../sanders_2018/120 Rocks\", nPixels, lambda x: resnet50.preprocess_input(np.expand_dims(x, axis=0)).squeeze())\n",
    "\n",
    "# load labels\n",
    "Y_120 = np.loadtxt(\"../sanders_2018/mds_120.txt\") # missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b652ff77-60a6-431b-a06d-cf4b09159d2e",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3abb124e-433e-464e-ba99-b50c0870ec5d",
   "metadata": {},
   "source": [
    "datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                    samplewise_center=False,\n",
    "                    featurewise_std_normalization=False,\n",
    "                    samplewise_std_normalization=False,\n",
    "                    zca_whitening=False,\n",
    "                    rotation_range=20,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    channel_shift_range=0.,\n",
    "                    fill_mode='nearest',\n",
    "                    cval=0.,\n",
    "                    horizontal_flip=True,\n",
    "                    vertical_flip=True)\n",
    "\n",
    "nEpochs = 10\n",
    "dropout = 0.5\n",
    "nEnsemble = 2\n",
    "          \n",
    "nDense = 256\n",
    "nLayers = 2\n",
    "loglr = -2.2200654426745987\n",
    "\n",
    "lr = 10 ** loglr\n",
    "nDim = 8\n",
    "batch_size = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2985ace7-1bb9-4f84-954a-92931000ef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of classes in the dataset\n",
    "num_classes = 2 # TODO needs to be changed to give coordinates\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8 \n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 15\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58d4c08-1998-45ad-9654-17dc5317a921",
   "metadata": {},
   "source": [
    "## Train models and save checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263fe463-997f-4982-8502-d51a2ac02bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiliaze the model\n",
    "\n",
    "model = torchvision.models.resnet50(pretrained = True)\n",
    "model.eval().to(device)\n",
    "\n",
    "set_parameter_requires_grad(model, feature_extract)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "input_size = 224\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08e4bca-c550-4f37-9f5d-1a4b14af39ce",
   "metadata": {},
   "source": [
    "Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bcdf56-b43a-44a6-b705-a5d8a58f3c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e01b0e-3377-4767-9815-4352edd5ec30",
   "metadata": {},
   "source": [
    "Run train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c096b839-012d-4a15-a05d-e067303daa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d397344a-12f6-4290-b04d-528c28512a5b",
   "metadata": {},
   "source": [
    "for e in range(nEnsemble):\n",
    "    #Build model\n",
    "    arch = resnet50.ResNet50(include_top=False, pooling='avg')\n",
    "    for layer in arch.layers:\n",
    "        layer.trainable = False    \n",
    "    \n",
    "    x = arch.output\n",
    "    x = Dropout(dropout)(x)\n",
    "    for lyr in range(nLayers):\n",
    "        x = Dense(nDense, activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "    x = Dense(nDim)(x)\n",
    "    \n",
    "    model = Model(inputs=arch.input, outputs=x)\n",
    "    \n",
    "    #Initial training\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=lr))\n",
    "    \n",
    "    checkpoint1 = ModelCheckpoint('intermediate_model.hdf5', save_best_only=True)\n",
    "\n",
    "    hist1 = model.fit(datagen.flow(X_train, Y_train, batch_size), \n",
    "                                steps_per_epoch=len(X_train) / batch_size,\n",
    "                                epochs=nEpochs,\n",
    "                                validation_data=(X_validate, Y_validate),\n",
    "                                callbacks=[checkpoint1],\n",
    "                                verbose=False)\n",
    "    \n",
    "    #Fine tuning\n",
    "    model = load_model(\"intermediate_model.hdf5\")\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    model.compile(optimizer=SGD(learning_rate=0.0001, momentum=0.9), loss='mean_squared_error')\n",
    "    \n",
    "    batch_size = 30 #reduce the batch size so that the gradients of all layers can fit in memory\n",
    "    \n",
    "    checkpoint2 = ModelCheckpoint('ensemble_{}.hdf5'.format(e), save_best_only=True)\n",
    "    \n",
    "    hist2 = model.fit(datagen.flow(X_train, Y_train, batch_size), \n",
    "                                steps_per_epoch=len(X_train) / batch_size,\n",
    "                                epochs=nEpochs,\n",
    "                                validation_data=(X_validate, Y_validate),\n",
    "                                callbacks=[checkpoint2],\n",
    "                                verbose=False)\n",
    "    \n",
    "    K.clear_session() #Clear tensorflow session to prevent memory issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cc080f-6539-4728-b77f-aee7a939f271",
   "metadata": {},
   "source": [
    "## Load checkpoints and get predictions for validation and test sets\n",
    "\n",
    "seems to be not sufficient / does not load to complete model as the results from an ensemble loaded this way are very poor (see also MDS notebook)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "566c1200-9420-4d52-927a-52ed23af8987",
   "metadata": {},
   "source": [
    "checkpoints_dir = \"\"\n",
    "\n",
    "validate_pred = np.zeros((nEnsemble, nTest, nDim))\n",
    "test_pred = np.zeros((nEnsemble, nTest, nDim))\n",
    "rocks_120_pred = np.zeros((nEnsemble, 120, nDim))\n",
    "\n",
    "for e in range(nEnsemble):\n",
    "    model = load_model(checkpoints_dir + \"ensemble_{}.hdf5\".format(e))\n",
    "    validate_pred[e,:] = model.predict(X_validate)\n",
    "    test_pred[e,:] = model.predict(X_test)\n",
    "    rocks_120_pred[e,:] = model.predict(X_120)\n",
    "    \n",
    "    K.clear_session()\n",
    "\n",
    "validate_prediction = np.mean(validate_pred, 0)\n",
    "test_prediction = np.mean(test_pred, 0)\n",
    "rocks_120_prediction = np.mean(rocks_120_pred, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884c4bd5-1bc7-427f-9712-d68e51cd876b",
   "metadata": {},
   "source": [
    "## Get MSE"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20e7c024-0d82-47fb-a0fc-31c654b45f15",
   "metadata": {},
   "source": [
    "print(mean_squared_error(Y_validate, validate_prediction))\n",
    "print(mean_squared_error(Y_test, test_prediction))\n",
    "print(mean_squared_error(Y_120, rocks_120_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0823a224-d473-404b-9387-c6310cef3ecf",
   "metadata": {},
   "source": [
    "## Get R²"
   ]
  },
  {
   "cell_type": "raw",
   "id": "699a74ee-f142-4e59-8a32-7c33c64c9a56",
   "metadata": {},
   "source": [
    "print(r2_score(Y_validate, validate_prediction))\n",
    "print(r2_score(Y_test, test_prediction))\n",
    "print(r2_score(Y_120, rocks_120_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b48874f-92a4-44f6-b563-6c754c3e6682",
   "metadata": {},
   "source": [
    "## Save predictions to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f64fb4a-19dc-4feb-aa3d-5017877c0d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_torch_pred_file = \"CNN Predictions/MDS Dimensions/cnn_torch_predicted_mds_120.txt\"\n",
    "\n",
    "np.savetxt(cnn_torch_pred_file, rocks_120_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35433c9-e773-4051-8b40-8053be09f41a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
