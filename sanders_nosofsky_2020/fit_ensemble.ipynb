{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ac78307-c58c-4f51-9394-72a35b8dc8e0",
   "metadata": {},
   "source": [
    "Notebook equivalent of `fit_ensemble.py`\n",
    "---\n",
    "\n",
    "* This program trains the ensemble of CNN models reported in https://link.springer.com/article/10.1007/s42113-020-00073-z\n",
    "    * It trains a model/ensemble on a 180 images training set of a 360 images dataset\n",
    "    * Makes predictions on\n",
    "        1. the 90 images validation set (part of the same 360 images set)\n",
    "        2. the 90 images test set (part of the same 360 images set)\n",
    "        3. the 120 images set (a different set)\n",
    "* Requires\n",
    "    * File `mds_360.txt` with labels (*missing*)\n",
    "    * Directory `360 Rocks/` with `*.jpg` images (*missing*)\n",
    "    * File `mds_120.txt` with labels (*missing*)\n",
    "    * Directory `120 Rocks/` with `*.jpg` images (*missing*)\n",
    "* Available\n",
    "    * Directory `120 Rock Images/` with 120 `*.png` images\n",
    "    * Directory `Similarity Judgements Data/` with similarity labels for the \"120 Rocks\" set as individual textfiles for each of the 85 participants: `rocks_similarity_120_*.txt`\n",
    "    * Directory `Categorization Data/` with category labels (1 = Igneous, 2 = Metamorphic, 4 = Mixed) for the \"120 Rocks\" set as individual textfiles for each of the 85 participants: `rocks_similarity_120_*_*.txt`\n",
    "    * File `MDS/mds_120_supplemental_dims.txt`\n",
    "* What to do?\n",
    "    - **a)** Ask for missing files?  \n",
    "    - **b)** Rewrite script to process what is available?  \n",
    "        * using the `*.png` images in the`120 Rock Images/` directory\n",
    "        * and using `mds_120_supplemental_dims.txt`  \n",
    "    \n",
    "    \n",
    "#### **Update from 2022/05/31: Missing data can found in this paper: https://link.springer.com/article/10.3758/s13428-017-0884-8**  \n",
    "* https://osf.io/w64fv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61702b5b-0873-4070-89af-1c0b19edd85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "nPixels = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25888384-b9b2-43e8-8157-dcd15ca61fc7",
   "metadata": {},
   "source": [
    "Original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1e28d7a-91f0-4417-bad0-cf4a38990e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nTest = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9a3bbd-7081-4b32-aa7a-2723da34e5a5",
   "metadata": {},
   "source": [
    "Replacement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7adb2f9e-2e81-474a-9f8c-87c946a987dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nTest = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c575f4ca-9a76-4c7f-9528-987a98d634f8",
   "metadata": {},
   "source": [
    "## Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a88f24-fcef-47e7-bc0a-6841ea0cb722",
   "metadata": {},
   "source": [
    "Original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3398881-bcc4-46b5-8699-6cb1f478826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories = [i for i in range(30) for j in range(12)] # creates 360 list items like so: [0, 0, 0, 0, ... 29, 29, 29, 29]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625bdcd1-b0fa-4633-bda2-10284494f209",
   "metadata": {},
   "source": [
    "Replacement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "677c57b5-2e80-4fd1-8622-f331a6e78ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [i for i in range(30) for j in range(4)] # creates 120 list items like so: [0, 0, 0, 0, ... 29, 29, 29, 29]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc824d1-e3b2-4fe8-9b31-507fd2c326e5",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37afe483-2908-4e60-8e24-9bc76943b16d",
   "metadata": {},
   "source": [
    "Original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b97c899-da5c-4399-ac69-362eae2c303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def load_images(directory, nPixels, preprocesser):\n",
    "#    \"\"\"\n",
    "#    Creates array-like data from a directory with image files for usage with Keras.\n",
    "#    \"\"\"\n",
    "#    \n",
    "#    X = []\n",
    "#    for subdir, dirs, files in os.walk(directory):\n",
    "#        for file in files:\n",
    "#            if file.endswith(\".jpg\"):\n",
    "#                img = load_img(os.path.join(subdir, file), target_size=(nPixels, nPixels))\n",
    "#                x = img_to_array(img)\n",
    "#                X.append(x)\n",
    "#    X = np.stack(X)\n",
    "#    X = preprocesser(X)\n",
    "#    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780dfa95-9256-4d3b-a518-efef0bc4830c",
   "metadata": {},
   "source": [
    "Replacement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2825ceaa-ef7c-48cb-90d5-d4c38d6945f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(directory, nPixels, preprocesser):\n",
    "    \"\"\"\n",
    "    Creates array-like data from a directory with image files for usage with Keras.\n",
    "    \"\"\"\n",
    "    \n",
    "    X = []\n",
    "    for subdir, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".png\"):\n",
    "                img = load_img(os.path.join(subdir, file), target_size=(nPixels, nPixels))\n",
    "                x = img_to_array(img)\n",
    "                X.append(x)\n",
    "    X = np.stack(X)\n",
    "    X = preprocesser(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442c0755-2bd7-485a-a1da-886e58709894",
   "metadata": {},
   "source": [
    "## Prepare 360 Rocks data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4607ae42-7aab-447e-94c8-acc1c5569fe6",
   "metadata": {},
   "source": [
    "Original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84a68534-f8b7-418d-ae23-e89a00aec802",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load image files\n",
    "#X = load_images(\"360 Rocks\", nPixels, lambda x: resnet50.preprocess_input(np.expand_dims(x, axis=0)).squeeze())\n",
    "#\n",
    "## load labels\n",
    "#mds_360 = np.loadtxt(\"mds_360.txt\") # missing\n",
    "#\n",
    "## split data: train vs test\n",
    "#(X_train_, X_test, \n",
    "# Y_train_, Y_test, \n",
    "# categories_train_, categories_test) = train_test_split(X, \n",
    "#                                                        mds_360, \n",
    "#                                                        categories,\n",
    "#                                                        test_size=nTest,\n",
    "#                                                        stratify=categories, \n",
    "#                                                        random_state=0)\n",
    "#\n",
    "## split train set again: train vs validate\n",
    "#(X_train, X_validate, \n",
    "# Y_train, Y_validate) = train_test_split(X_train_, \n",
    "#                                         Y_train_, \n",
    "#                                         test_size=nTest,\n",
    "#                                         stratify=categories_train_, \n",
    "#                                         random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42a513c-decb-4719-b677-ca929362a2bd",
   "metadata": {},
   "source": [
    "Replacement is the available 120 Rocks images set in png format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69738bac-9af6-4182-bb80-03cdb0939a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image files\n",
    "X = load_images(\"120 Rock Images\", nPixels, lambda x: resnet50.preprocess_input(np.expand_dims(x, axis=0)).squeeze())\n",
    "\n",
    "# load labels\n",
    "Y = np.loadtxt(\"MDS/mds_120_supplemental_dims.txt\", skiprows=1)\n",
    "\n",
    "# split data: train vs test\n",
    "(X_train_, X_test, \n",
    " Y_train_, Y_test, \n",
    " categories_train_, categories_test) = train_test_split(X, \n",
    "                                                        Y, \n",
    "                                                        categories,\n",
    "                                                        test_size=nTest,\n",
    "                                                        stratify=categories, \n",
    "                                                        random_state=0)\n",
    "\n",
    "# split train set again: train vs validate\n",
    "(X_train, X_validate, \n",
    " Y_train, Y_validate) = train_test_split(X_train_, \n",
    "                                         Y_train_, \n",
    "                                         test_size=nTest,\n",
    "                                         stratify=categories_train_, \n",
    "                                         random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3f8eef-b65e-48c5-b32a-80f75ae68a9b",
   "metadata": {},
   "source": [
    "## Prepare 120 Rocks data\n",
    "\n",
    "no train, test, validate splits ...will be later used only for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aac8a5e-dd4f-4c60-b399-e6f7dd3c33a5",
   "metadata": {},
   "source": [
    "Original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e06f74f0-00e5-4cc4-a8b7-4ee40425ce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load image files\n",
    "#X_120 = load_images(\"120 Rocks\", nPixels, lambda x: resnet50.preprocess_input(np.expand_dims(x, axis=0)).squeeze())\n",
    "#\n",
    "## load labels\n",
    "#Y_120 = np.loadtxt(\"mds_120.txt\") # missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c0dbdf-c0c0-474e-b892-7b876495b123",
   "metadata": {},
   "source": [
    "No Replacement, will just be left out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b652ff77-60a6-431b-a06d-cf4b09159d2e",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08501f00-a5e4-4a71-a6bc-ca214e67325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                    samplewise_center=False,\n",
    "                    featurewise_std_normalization=False,\n",
    "                    samplewise_std_normalization=False,\n",
    "                    zca_whitening=False,\n",
    "                    rotation_range=20,\n",
    "                    width_shift_range=0.2,\n",
    "                    height_shift_range=0.2,\n",
    "                    shear_range=0.2,\n",
    "                    zoom_range=0.2,\n",
    "                    channel_shift_range=0.,\n",
    "                    fill_mode='nearest',\n",
    "                    cval=0.,\n",
    "                    horizontal_flip=True,\n",
    "                    vertical_flip=True)\n",
    "\n",
    "nEpochs = 10\n",
    "dropout = 0.5\n",
    "nEnsemble = 2\n",
    "          \n",
    "nDense = 256\n",
    "nLayers = 2\n",
    "loglr = -2.2200654426745987\n",
    "\n",
    "lr = 10 ** loglr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee95286a-f1b8-4137-b5bb-9a06cd1c7e2b",
   "metadata": {},
   "source": [
    "Original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e58ccf49-7f64-41ea-af5c-8f63ea9e013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nDim = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc1dc82-a5fa-446d-a89f-a82294e90096",
   "metadata": {},
   "source": [
    "Replacement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00ac65d9-8a5f-45bf-b0e5-69f7a156fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nDim = 13 # we have 5 extra dimensions in our file mds_120_supplemental_dims.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbc45a4-43eb-45fe-89ff-1273dfedb617",
   "metadata": {},
   "source": [
    "Original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7668f343-3eec-468d-9911-6727bb8d31fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57678a7-4335-425f-9802-c88d1a2477b3",
   "metadata": {},
   "source": [
    "Replacement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d19e593e-f4bb-44b8-88d3-8d0d2c3b3752",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58d4c08-1998-45ad-9654-17dc5317a921",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108761a5-9d10-42e7-8ec5-4ea16e3041bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(nEnsemble):\n",
    "    #Build model\n",
    "    arch = resnet50.ResNet50(include_top=False, pooling='avg')\n",
    "    for layer in arch.layers:\n",
    "        layer.trainable = False    \n",
    "    \n",
    "    x = arch.output\n",
    "    x = Dropout(dropout)(x)\n",
    "    for lyr in range(nLayers):\n",
    "        x = Dense(nDense, activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(dropout)(x)\n",
    "    x = Dense(nDim)(x)\n",
    "    \n",
    "    model = Model(inputs=arch.input, outputs=x)\n",
    "    \n",
    "    #Initial training\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=lr))\n",
    "    \n",
    "    checkpoint1 = ModelCheckpoint('intermediate_model.hdf5', save_best_only=True)\n",
    "\n",
    "    hist1 = model.fit(datagen.flow(X_train, Y_train, batch_size), \n",
    "                                steps_per_epoch=len(X_train) / batch_size,\n",
    "                                epochs=nEpochs,\n",
    "                                validation_data=(X_validate, Y_validate),\n",
    "                                callbacks=[checkpoint1],\n",
    "                                verbose=False)\n",
    "    \n",
    "    #Fine tuning\n",
    "    model = load_model(\"intermediate_model.hdf5\")\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    model.compile(optimizer=SGD(learning_rate=0.0001, momentum=0.9), loss='mean_squared_error')\n",
    "    \n",
    "    batch_size = 30 #reduce the batch size so that the gradients of all layers can fit in memory\n",
    "    \n",
    "    checkpoint2 = ModelCheckpoint('ensemble_{}.hdf5'.format(e), save_best_only=True)\n",
    "    \n",
    "    hist2 = model.fit(datagen.flow(X_train, Y_train, batch_size), \n",
    "                                steps_per_epoch=len(X_train) / batch_size,\n",
    "                                epochs=nEpochs,\n",
    "                                validation_data=(X_validate, Y_validate),\n",
    "                                callbacks=[checkpoint2],\n",
    "                                verbose=False)\n",
    "    \n",
    "    K.clear_session() #Clear tensorflow session to prevent memory issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cc080f-6539-4728-b77f-aee7a939f271",
   "metadata": {},
   "source": [
    "## Get predictions for validation and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a0d5e8-1ea1-48d0-b0a2-01144c308a82",
   "metadata": {},
   "source": [
    "Original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ef99113-b833-466f-9164-1c7f45fd2f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validate_pred = np.zeros((nEnsemble, nTest, nDim))\n",
    "#test_pred = np.zeros((nEnsemble, nTest, nDim))\n",
    "#rocks_120_pred = np.zeros((nEnsemble, 120, nDim))\n",
    "#\n",
    "#for e in range(nEnsemble):\n",
    "#    model = load_model(\"ensemble_{}.hdf5\".format(e))\n",
    "#    validate_pred[e,:] = model.predict(X_validate)\n",
    "#    test_pred[e,:] = model.predict(X_test)\n",
    "#    rocks_120_pred[e,:] = model.predict(X_120)\n",
    "#    \n",
    "#    K.clear_session()\n",
    "#\n",
    "#validate_prediction = np.mean(validate_pred, 0)\n",
    "#test_prediction = np.mean(test_pred, 0)\n",
    "#rocks_120_prediction = np.mean(rocks_120_pred, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80e0bc7-084d-419a-a3b2-5cbb8fa66cd7",
   "metadata": {},
   "source": [
    "Replacement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fefc015-8c1f-45f8-bae8-9d60430e1dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "validate_pred = np.zeros((nEnsemble, nTest, nDim))\n",
    "test_pred = np.zeros((nEnsemble, nTest, nDim))\n",
    "\n",
    "for e in range(nEnsemble):\n",
    "    model = load_model(\"ensemble_{}.hdf5\".format(e))\n",
    "    validate_pred[e,:] = model.predict(X_validate)\n",
    "    test_pred[e,:] = model.predict(X_test)\n",
    "    \n",
    "    K.clear_session()\n",
    "\n",
    "validate_prediction = np.mean(validate_pred, 0)\n",
    "test_prediction = np.mean(test_pred, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884c4bd5-1bc7-427f-9712-d68e51cd876b",
   "metadata": {},
   "source": [
    "## Get MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02cac1f-2d8c-4a54-9c5d-af23a0967868",
   "metadata": {},
   "source": [
    "Original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e0cba5-aaf8-4f28-b742-b69c6fb18bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(mean_squared_error(Y_validate, validate_prediction))\n",
    "#print(mean_squared_error(Y_test, test_prediction))\n",
    "#print(mean_squared_error(Y_120, rocks_120_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5aa885-2275-4da3-ac31-7738160d14d5",
   "metadata": {},
   "source": [
    "Replacement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61ed4462-54a0-4b13-b781-3b44ad8b0060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0210778242600975\n",
      "4.748088967288659\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(Y_validate, validate_prediction))\n",
    "print(mean_squared_error(Y_test, test_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0823a224-d473-404b-9387-c6310cef3ecf",
   "metadata": {},
   "source": [
    "## Get R²"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed4e9c-119c-4473-ba3e-963313554e18",
   "metadata": {},
   "source": [
    "Original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7825d48-9155-4d32-b899-45b8f124eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(r2_score(Y_validate, validate_prediction))\n",
    "#print(r2_score(Y_test, test_prediction))\n",
    "#print(r2_score(Y_120, rocks_120_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de4aa98-954c-485f-8625-ca8d0eabbc29",
   "metadata": {},
   "source": [
    "Replacement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6fd62ba-3b6b-419b-8957-759c82ecfd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.2933656778110103\n",
      "-0.7927527839019183\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(Y_validate, validate_prediction))\n",
    "print(r2_score(Y_test, test_prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
