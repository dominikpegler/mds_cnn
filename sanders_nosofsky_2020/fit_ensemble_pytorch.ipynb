{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit CNN in PyTorch\n",
    "===\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">Optimizations to do:<ul><li>Image augmentation: not applied on single images but on a batch for better performance.</li><li>Test newly implemented image augmentation methods: rotation range to 360Â°, shear, random resize crops more balanced, color, blur, contrast</li><li>Image augmentation: Discuss impact of augmentation on the individual MDS dimensions (Dimensions, \"lightness\", \"shape\", \"organisation\" (or a possible dimension \"size\") impaired by harsh crops, resizings, brightness?).</li><li>Learning rate: Discuss usage of lr scheduler (torch.optim.lr_scheduler)</li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torchmetrics import R2Score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import cv2\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from skimage import io, transform\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# number of models\n",
    "n_ensemble = 10\n",
    "\n",
    "# size of test and validation set\n",
    "n_test = 90\n",
    "\n",
    "# Number of dimensions in the dataset\n",
    "n_dim = 8\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size_im = 90\n",
    "batch_size_ft = 30\n",
    "\n",
    "# Number of epochs to train for \n",
    "num_epochs_im = 500\n",
    "num_epochs_ft = 500\n",
    "\n",
    "# where would we use these in pytorch? in keras they are used to create layers for the intermediate model\n",
    "dropout = 0.5 \n",
    "n_dense = 256\n",
    "n_layers = 2\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model, \n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract_im = True\n",
    "feature_extract_ft = False\n",
    "\n",
    "input_size = 224\n",
    "\n",
    "loglr = -2.2200654426745987\n",
    "lr_im = 1 * 10 ** loglr\n",
    "lr_ft = 1e-3\n",
    "\n",
    "# create categories of stones for stratified train test split\n",
    "categories = [i for i in range(30) for j in range(12)] # creates 360 list items like so: [0, 0, 0, 0, ... 29, 29, 29, 29]\n",
    "\n",
    "IMG_360 = '../sanders_2018/360 Rocks/'\n",
    "IMG_120 = '../sanders_2018/120 Rocks/'\n",
    "MDS_360 = '../finetuning_torchvision_data/mds_360.csv'\n",
    "CHECKPOINTS = 'CNN_checkpoints/'\n",
    "PATH_IM = CHECKPOINTS + 'state_dict_intermediate_model.pt'\n",
    "PATH_FT = CHECKPOINTS + 'state_dict_finetuned_model.pt'\n",
    "\n",
    "\n",
    "print(\"Device is\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=14, is_inception=False):\n",
    "    \"\"\"\n",
    "    handles the training and validation of a given model. At the end of\n",
    "    training returns the best performing model. After each epoch, the training and validation\n",
    "    accuracies are printed\n",
    "    \"\"\"\n",
    "    \n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    lrs = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = None\n",
    "    \n",
    "    r2score = R2Score(num_outputs=8).to(device)\n",
    "    \n",
    "    early_stopping = EarlyStopping()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {str(epoch + 1).rjust(len(str(num_epochs)))}/{num_epochs}', end=\": \")\n",
    "        #print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_r2 = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    score = r2score(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        # scheduler.step()\n",
    "                        lr = optimizer.param_groups[0][\"lr\"]\n",
    "                        lrs.append(lr)\n",
    "\n",
    "                # statistics \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_r2 += score.item() * inputs.size(0)\n",
    "                \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset) \n",
    "            epoch_acc = running_r2 / len(dataloaders[phase].dataset) \n",
    "            # print only if phase is validation\n",
    "            if phase == \"val\":\n",
    "                print(f'Loss = {epoch_loss: .4f}, Score = {epoch_acc: .4f}, lr = {lr: .4e}')\n",
    "                early_stopping(epoch_loss)\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and best_acc == None:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val' and best_acc < epoch_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        # early stopping if no improvement in the last 20 epochs\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopped.\")\n",
    "            break\n",
    "                \n",
    "\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history, lrs\n",
    "\n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    \"\"\"\n",
    "    This helper function sets the ``.requires_grad`` attribute of the\n",
    "    parameters in the model to False when we are feature extracting.\n",
    "    \"\"\"\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    else:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "    return None\n",
    "\n",
    "\n",
    "class RocksData(datasets.VisionDataset):\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        super(RocksData).__init__()\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, ix):\n",
    "        img_path = self.root_dir + \"/\" + self.df.iloc[ix,0]\n",
    "        img = cv2.imread(img_path)\n",
    "        img = PIL.Image.fromarray(img)  \n",
    "        label = deepcopy(self.df.iloc[ix,1:].tolist())\n",
    "        label = torch.tensor(label).float()\n",
    "        img = self.transform(img)\n",
    "        return img.to(device), label\n",
    " \n",
    "    \n",
    "class PredictionData(datasets.VisionDataset): # TODO: lots of redundant code. integrate this into above RocksData dataset\n",
    "    def __init__(self, img_paths):\n",
    "        super(PredictionData).__init__()\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                             std=[0.229, 0.224, 0.225])\n",
    "        self.img_paths = img_paths\n",
    "    def __len__(self): return len(self.img_paths)\n",
    "    def __getitem__(self, ix):\n",
    "        img = cv2.imread(self.img_paths[ix])/255.\n",
    "        img = self.preprocess_input(img)\n",
    "        return img\n",
    "    def preprocess_input(self, img):\n",
    "        img = cv2.resize(img, (224,224))\n",
    "        img = torch.tensor(img).permute(2,0,1)\n",
    "        img = self.normalize(img).float()\n",
    "        return img.to(device) \n",
    "    \n",
    "    \n",
    "def get_criterion(loss_name):\n",
    "    \"\"\"\n",
    "    Returns the optimizer\n",
    "    \"\"\"\n",
    "    if loss_name == \"L1\":\n",
    "        return torch.nn.L1Loss()\n",
    "    elif loss_name == \"L2\":\n",
    "        return torch.nn.MSELoss()\n",
    "    elif loss_name == \"smooth_L1\":\n",
    "        return torch.nn.SmoothL1Loss()\n",
    "    elif loss_name == \"huber\":\n",
    "        return torch.nn.HuberLoss()\n",
    "    else:\n",
    "        raise Exception(\"No valid loss_name entered!\")\n",
    "        \n",
    "\n",
    "def load_pretrained_model(e=None, model_type=None):\n",
    "    \n",
    "    if (model_type == None) | (model_type == \"resnet\"):\n",
    "        model = models.resnet50()\n",
    "    elif model_type == \"regnet\":\n",
    "        model = models.regnet_y_16gf()\n",
    "    set_parameter_requires_grad(model, feature_extract_ft)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    new_layers = OutputLayers(n_layers, num_ftrs, n_dense, dropout)\n",
    "    model.fc = new_layers # replace last layer\n",
    "    \n",
    "    if model_type == None:\n",
    "        if e == None:\n",
    "            checkpoint = torch.load(CHECKPOINTS + f'state_dict_intermediate_model.pt', map_location=device)\n",
    "        else:\n",
    "            checkpoint = torch.load(CHECKPOINTS + f'state_dict_ensemble_model_{e+1}.pt', map_location=device)\n",
    "    else:\n",
    "        checkpoint = torch.load(CHECKPOINTS + f'state_dict_intermediate_{model_type}.pt', map_location=device)\n",
    "    \n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "    # Send the model to GPU\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "def predict(model, data_loader, unlabeled=False):\n",
    "    \"\"\"Computes predictions for a given mnodel and dataset\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    outputs = list()\n",
    "    since = time.time()\n",
    "    with torch.no_grad():\n",
    "        if unlabeled:\n",
    "            for inputs in data_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                output = model(inputs)\n",
    "                outputs.append(output.to(\"cpu\").squeeze().numpy())\n",
    "        else:\n",
    "            for inputs, _ in data_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                output = model(inputs)\n",
    "                outputs.append(output.to(\"cpu\").squeeze().numpy())\n",
    "\n",
    "    return np.array(outputs)\n",
    "\n",
    "\n",
    "class EarlyStopping():\n",
    "    def __init__(self, tolerance=20):\n",
    "\n",
    "        self.tolerance = tolerance\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "        self.best_loss = np.nan\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss >= self.best_loss:\n",
    "            self.counter +=1\n",
    "            if self.counter >= self.tolerance:  \n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define image transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define image transformations\n",
    "#data_transforms = {\n",
    "#    'train': transforms.Compose([\n",
    "#        transforms.RandomResizedCrop(input_size),\n",
    "#        transforms.RandomHorizontalFlip(),\n",
    "#        transforms.RandomVerticalFlip(),\n",
    "#        transforms.RandomAffine(degrees=20, translate=(0.2, 0.2), shear=(0.2, 0.2, 0.2, 0.2), scale=(0.8, 1.2)),\n",
    "#        transforms.ToTensor(),\n",
    "#        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#    ]),\n",
    "#    'val': transforms.Compose([\n",
    "#        transforms.Resize(input_size),\n",
    "#        transforms.CenterCrop(input_size),\n",
    "#        transforms.ToTensor(),\n",
    "#        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#    ]),\n",
    "#}\n",
    "\n",
    "# define image transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size, scale=(1, 1), ratio=(.33, 2.5)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomAffine(degrees=360, translate=(0.05, 0.05), shear=(-16, 16, -16, 16), scale=(.78, .89)),\n",
    "        transforms.ColorJitter(brightness=(.95, 1.05), contrast=(.9, 1.1), saturation=(0.95, 1.15)), # new\n",
    "        transforms.GaussianBlur(kernel_size=(1, 1), sigma=(.01, .5)), # new\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),    \n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(MDS_360)\n",
    "\n",
    "\n",
    "# split data: train vs test\n",
    "(train, test,\n",
    "categories_train_, categories_test) = train_test_split(df,\n",
    "                                                       categories,\n",
    "                                                       test_size=n_test,\n",
    "                                                       stratify=categories,\n",
    "                                                       random_state=0)\n",
    "\n",
    "# split train set again: train vs validate\n",
    "train, val = train_test_split(train,\n",
    "                              test_size=n_test,\n",
    "                              stratify=categories_train_, \n",
    "                              random_state=0)\n",
    "\n",
    "# create image datasets\n",
    "train_dataset = RocksData(train.reset_index(drop=True), root_dir=IMG_360, transform=data_transforms[\"train\"])\n",
    "val_dataset = RocksData(val.reset_index(drop=True), root_dir=IMG_360, transform=data_transforms[\"val\"])\n",
    "test_dataset = RocksData(test.reset_index(drop=True), root_dir=IMG_360, transform=data_transforms[\"val\"])\n",
    "pred_dataset = PredictionData(glob(IMG_120+'*.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapt model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the final layers look like in Keras:\n",
    "\n",
    "```\n",
    "__________________________________________________________________________________________________\n",
    " Layer (type)                   Output Shape         Param #     Connected to                     \n",
    "==================================================================================================\n",
    "\n",
    "avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
    " 2D)                                                                                              \n",
    "                                                                                                  \n",
    " dropout (Dropout)              (None, 2048)         0           ['avg_pool[0][0]']               \n",
    "                                                                                                  \n",
    " dense (Dense)                  (None, 256)          524544      ['dropout[0][0]']                \n",
    "                                                                                                  \n",
    " batch_normalization (BatchNorm  (None, 256)         1024        ['dense[0][0]']                  \n",
    " alization)                                                                                       \n",
    "                                                                                                  \n",
    " dropout_1 (Dropout)            (None, 256)          0           ['batch_normalization[0][0]']    \n",
    "                                                                                                  \n",
    " dense_1 (Dense)                (None, 256)          65792       ['dropout_1[0][0]']              \n",
    "                                                                                                  \n",
    " batch_normalization_1 (BatchNo  (None, 256)         1024        ['dense_1[0][0]']                \n",
    " rmalization)                                                                                     \n",
    "                                                                                                  \n",
    " dropout_2 (Dropout)            (None, 256)          0           ['batch_normalization_1[0][0]']  \n",
    "                                                                                                  \n",
    " dense_2 (Dense)                (None, 8)            2056        ['dropout_2[0][0]']       \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "class OutputLayers(nn.Sequential):\n",
    "    def __init__(self, n_layers, num_ftrs, n_dense, dropout):\n",
    "        super().__init__(self.init_modules(n_layers, num_ftrs, n_dense, dropout))\n",
    "\n",
    "\n",
    "    def init_modules(self, n_layers, num_ftrs, n_dense, dropout):\n",
    "        modules = OrderedDict()\n",
    "        \n",
    "        i = 0\n",
    "        modules[f\"dropout_{i}\"] = nn.Dropout(p=dropout)\n",
    "        modules[f\"fc_{i}\"] = nn.Linear(num_ftrs, n_dense)\n",
    "        \n",
    "        for i in range(1, n_layers):           \n",
    "            modules[f\"relu_{i}\"] = nn.ReLU(inplace=True)\n",
    "            modules[f\"batchnorm_{i}\"] = nn.BatchNorm1d(n_dense)\n",
    "            modules[f\"dropout_{i}\"] = nn.Dropout(p=dropout)\n",
    "            modules[f\"fc_{i}\"] = nn.Linear(n_dense, n_dense)\n",
    "\n",
    "        modules[f\"relu_{i+1}\"] = nn.ReLU(inplace=True)\n",
    "        modules[f\"batchnorm_{i+1}\"] = nn.BatchNorm1d(n_dense)\n",
    "        modules[f\"dropout_{i+1}\"] = nn.Dropout(p=dropout)\n",
    "        modules[f\"fc_{i+1}\"] = nn.Linear(n_dense, n_dim)\n",
    "\n",
    "        return modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train one model ...\n",
    "... for testing purposes, comparing learning rates etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intermediate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/500: Loss =  6.4734, Score = -0.0080, lr =  6.0247e-03\n",
      "Epoch   2/500: Loss =  5.8572, Score =  0.0729, lr =  6.0247e-03\n",
      "Epoch   3/500: Loss =  5.0459, Score =  0.2013, lr =  6.0247e-03\n",
      "Epoch   4/500: Loss =  5.0327, Score =  0.2100, lr =  6.0247e-03\n",
      "Epoch   5/500: Loss =  4.0765, Score =  0.3561, lr =  6.0247e-03\n",
      "Epoch   6/500: Loss =  3.7778, Score =  0.3981, lr =  6.0247e-03\n",
      "Epoch   7/500: Loss =  3.7204, Score =  0.3944, lr =  6.0247e-03\n",
      "Epoch   8/500: Loss =  3.6979, Score =  0.3900, lr =  6.0247e-03\n",
      "Epoch   9/500: "
     ]
    }
   ],
   "source": [
    "num_epochs_one = 500\n",
    "lr_one = 6.0247e-03\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "model_type = \"resnet\" # \"resnet\"\n",
    "\n",
    "# Intermediate model\n",
    "\n",
    "if model_type == \"resnet\":\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "elif model_type == \"regnet\":\n",
    "    model = models.regnet_y_16gf(weights=models.RegNet_Y_16GF_Weights.IMAGENET1K_SWAG_E2E_V1)\n",
    "    \n",
    "set_parameter_requires_grad(model, feature_extract_im)\n",
    "num_ftrs = model.fc.in_features\n",
    "new_layers = OutputLayers(n_layers, num_ftrs, n_dense, dropout)\n",
    "model.fc = new_layers # replace last layer\n",
    "\n",
    "# Send the model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# create dataloaders with specific batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size_ft)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size_ft)\n",
    "dataloaders_dict = {\"train\":train_loader,\"val\":val_loader}\n",
    "\n",
    "# Create Optimizer and define params to update\n",
    "params_to_update = model.parameters()\n",
    "if feature_extract_im:\n",
    "    params_to_update = []\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "\n",
    "\n",
    "# Instantiate optimizer for intermediate model\n",
    "optimizer = optim.Adam(params_to_update, lr = lr_one)\n",
    "\n",
    "# learning rate scheduler\n",
    "#scheduler = lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.95, verbose=True)\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = get_criterion(\"L2\")\n",
    "\n",
    "# Train and evaluate intermediate model\n",
    "model, hist, lrs = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs_one)\n",
    "\n",
    "# Save intermediate model\n",
    "torch.save(model.state_dict(), CHECKPOINTS + f'state_dict_intermediate_{model_type}.pt')\n",
    "\n",
    "# Plot learning curve\n",
    "plt.plot(hist)\n",
    "plt.title(f'Intermediate model: {model_type}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuned model (needs weights of intermediate model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs_one = 500\n",
    "lr_one = 1e-3\n",
    "\n",
    "#torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# load intermediate model\n",
    "\n",
    "model_type = \"resnet\" # \"resnet\" or None\n",
    "\n",
    "model = load_pretrained_model(model_type=model_type)\n",
    "\n",
    "# create dataloaders with specific batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size_ft)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size_ft)\n",
    "dataloaders_dict = {\"train\":train_loader,\"val\":val_loader}\n",
    "\n",
    "# Create Optimizer and define params to update\n",
    "params_to_update = model.parameters()\n",
    "if feature_extract_ft:\n",
    "    params_to_update = []\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "\n",
    "# Instantiate optimizer for finetuning\n",
    "# optimizer = optim.SGD(params_to_update, lr=lr_one, momentum=0.9)\n",
    "optimizer = optim.Adagrad(params_to_update, lr=lr_one)\n",
    "   \n",
    "# Setup the loss fxn\n",
    "criterion = get_criterion(\"L2\")\n",
    "\n",
    "# Train and evaluate fine tuned model\n",
    "model, hist, lrs = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs_one)\n",
    "\n",
    "# Save finetuned model\n",
    "#torch.save(model.state_dict(), CHECKPOINTS + f'state_dict_finetuned_{model_type}.pt')\n",
    "\n",
    "# Plot learning curve\n",
    "plt.plot(hist)\n",
    "plt.title(f'Finetuned {model_type}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/500: Loss =  3.1105, Score =  0.4681, lr =  1.0000e-03\n",
      "Epoch   2/500: Loss =  2.4504, Score =  0.5756, lr =  1.0000e-03\n",
      "Epoch   3/500: Loss =  2.1186, Score =  0.6313, lr =  1.0000e-03\n",
      "Epoch   4/500: Loss =  2.1296, Score =  0.6373, lr =  1.0000e-03\n",
      "Epoch   5/500: Loss =  2.0056, Score =  0.6528, lr =  1.0000e-03\n",
      "Epoch   6/500: Loss =  1.9911, Score =  0.6589, lr =  1.0000e-03\n",
      "Epoch   7/500: Loss =  1.9528, Score =  0.6600, lr =  1.0000e-03\n",
      "Epoch   8/500: Loss =  1.9565, Score =  0.6581, lr =  1.0000e-03\n",
      "Epoch   9/500: Loss =  1.9444, Score =  0.6644, lr =  1.0000e-03\n",
      "Epoch  10/500: Loss =  1.9403, Score =  0.6649, lr =  1.0000e-03\n",
      "Epoch  11/500: Loss =  1.8179, Score =  0.6826, lr =  1.0000e-03\n",
      "Epoch  12/500: Loss =  1.7961, Score =  0.6854, lr =  1.0000e-03\n",
      "Epoch  13/500: Loss =  1.7821, Score =  0.6886, lr =  1.0000e-03\n",
      "Epoch  14/500: Loss =  1.7764, Score =  0.6876, lr =  1.0000e-03\n",
      "Epoch  15/500: Loss =  1.7422, Score =  0.6946, lr =  1.0000e-03\n",
      "Epoch  16/500: Loss =  1.7102, Score =  0.7003, lr =  1.0000e-03\n",
      "Epoch  17/500: Loss =  1.7410, Score =  0.6947, lr =  1.0000e-03\n",
      "Epoch  18/500: Loss =  1.7451, Score =  0.6949, lr =  1.0000e-03\n",
      "Epoch  19/500: Loss =  1.7687, Score =  0.6900, lr =  1.0000e-03\n",
      "Epoch  20/500: Loss =  1.7388, Score =  0.6937, lr =  1.0000e-03\n",
      "Epoch  21/500: Loss =  1.7038, Score =  0.6994, lr =  1.0000e-03\n",
      "Epoch  22/500: Loss =  1.6958, Score =  0.7007, lr =  1.0000e-03\n",
      "Epoch  23/500: Loss =  1.6952, Score =  0.7013, lr =  1.0000e-03\n",
      "Epoch  24/500: Loss =  1.6792, Score =  0.7038, lr =  1.0000e-03\n",
      "Epoch  25/500: Loss =  1.6783, Score =  0.7041, lr =  1.0000e-03\n",
      "Epoch  26/500: Loss =  1.6739, Score =  0.7056, lr =  1.0000e-03\n",
      "Epoch  27/500: Loss =  1.6597, Score =  0.7097, lr =  1.0000e-03\n",
      "Epoch  28/500: Loss =  1.6221, Score =  0.7155, lr =  1.0000e-03\n",
      "Epoch  29/500: Loss =  1.6207, Score =  0.7139, lr =  1.0000e-03\n",
      "Epoch  30/500: Loss =  1.6014, Score =  0.7168, lr =  1.0000e-03\n",
      "Epoch  31/500: Loss =  1.6331, Score =  0.7116, lr =  1.0000e-03\n",
      "Epoch  32/500: Loss =  1.6307, Score =  0.7124, lr =  1.0000e-03\n",
      "Epoch  33/500: Loss =  1.6401, Score =  0.7115, lr =  1.0000e-03\n",
      "Epoch  34/500: Loss =  1.5965, Score =  0.7191, lr =  1.0000e-03\n",
      "Epoch  35/500: Loss =  1.6206, Score =  0.7156, lr =  1.0000e-03\n",
      "Epoch  36/500: Loss =  1.6070, Score =  0.7155, lr =  1.0000e-03\n",
      "Epoch  37/500: Loss =  1.6162, Score =  0.7148, lr =  1.0000e-03\n",
      "Epoch  38/500: Loss =  1.6206, Score =  0.7150, lr =  1.0000e-03\n",
      "Epoch  39/500: Loss =  1.6078, Score =  0.7172, lr =  1.0000e-03\n",
      "Epoch  40/500: Loss =  1.6665, Score =  0.7080, lr =  1.0000e-03\n",
      "Epoch  41/500: Loss =  1.6452, Score =  0.7113, lr =  1.0000e-03\n",
      "Epoch  42/500: Loss =  1.6336, Score =  0.7123, lr =  1.0000e-03\n",
      "Epoch  43/500: Loss =  1.6341, Score =  0.7119, lr =  1.0000e-03\n",
      "Epoch  44/500: Loss =  1.6295, Score =  0.7131, lr =  1.0000e-03\n",
      "Epoch  45/500: Loss =  1.6030, Score =  0.7184, lr =  1.0000e-03\n",
      "Epoch  46/500: Loss =  1.6073, Score =  0.7166, lr =  1.0000e-03\n",
      "Epoch  47/500: Loss =  1.6170, Score =  0.7151, lr =  1.0000e-03\n",
      "Epoch  48/500: Loss =  1.6134, Score =  0.7156, lr =  1.0000e-03\n",
      "Epoch  49/500: Loss =  1.6316, Score =  0.7131, lr =  1.0000e-03\n",
      "Epoch  50/500: Loss =  1.6092, Score =  0.7170, lr =  1.0000e-03\n",
      "Epoch  51/500: Loss =  1.6034, Score =  0.7185, lr =  1.0000e-03\n",
      "Epoch  52/500: Loss =  1.6150, Score =  0.7164, lr =  1.0000e-03\n",
      "Epoch  53/500: Loss =  1.5833, Score =  0.7206, lr =  1.0000e-03\n",
      "Epoch  54/500: Loss =  1.5720, Score =  0.7224, lr =  1.0000e-03\n",
      "Epoch  55/500: Loss =  1.5953, Score =  0.7185, lr =  1.0000e-03\n",
      "Epoch  56/500: Loss =  1.5679, Score =  0.7220, lr =  1.0000e-03\n",
      "Epoch  57/500: Loss =  1.6070, Score =  0.7158, lr =  1.0000e-03\n",
      "Epoch  58/500: Loss =  1.5744, Score =  0.7218, lr =  1.0000e-03\n",
      "Epoch  59/500: Loss =  1.5840, Score =  0.7201, lr =  1.0000e-03\n",
      "Epoch  60/500: Loss =  1.5716, Score =  0.7225, lr =  1.0000e-03\n",
      "Epoch  61/500: Loss =  1.5692, Score =  0.7237, lr =  1.0000e-03\n",
      "Epoch  62/500: Loss =  1.5559, Score =  0.7253, lr =  1.0000e-03\n",
      "Epoch  63/500: Loss =  1.5653, Score =  0.7243, lr =  1.0000e-03\n",
      "Epoch  64/500: Loss =  1.5973, Score =  0.7202, lr =  1.0000e-03\n",
      "Epoch  65/500: Loss =  1.5759, Score =  0.7233, lr =  1.0000e-03\n",
      "Epoch  66/500: Loss =  1.5500, Score =  0.7272, lr =  1.0000e-03\n",
      "Epoch  67/500: Loss =  1.5605, Score =  0.7266, lr =  1.0000e-03\n",
      "Epoch  68/500: Loss =  1.5766, Score =  0.7249, lr =  1.0000e-03\n",
      "Epoch  69/500: Loss =  1.5651, Score =  0.7265, lr =  1.0000e-03\n",
      "Epoch  70/500: Loss =  1.5805, Score =  0.7233, lr =  1.0000e-03\n",
      "Epoch  71/500: Loss =  1.5647, Score =  0.7250, lr =  1.0000e-03\n",
      "Epoch  72/500: Loss =  1.5551, Score =  0.7261, lr =  1.0000e-03\n",
      "Epoch  73/500: Loss =  1.5428, Score =  0.7278, lr =  1.0000e-03\n",
      "Epoch  74/500: Loss =  1.5392, Score =  0.7296, lr =  1.0000e-03\n",
      "Epoch  75/500: Loss =  1.5516, Score =  0.7284, lr =  1.0000e-03\n",
      "Epoch  76/500: Loss =  1.5604, Score =  0.7269, lr =  1.0000e-03\n",
      "Epoch  77/500: Loss =  1.5571, Score =  0.7264, lr =  1.0000e-03\n",
      "Epoch  78/500: Loss =  1.5329, Score =  0.7305, lr =  1.0000e-03\n",
      "Epoch  79/500: Loss =  1.5292, Score =  0.7306, lr =  1.0000e-03\n",
      "Epoch  80/500: Loss =  1.5562, Score =  0.7266, lr =  1.0000e-03\n",
      "Epoch  81/500: Loss =  1.5517, Score =  0.7270, lr =  1.0000e-03\n",
      "Epoch  82/500: Loss =  1.5290, Score =  0.7305, lr =  1.0000e-03\n",
      "Epoch  83/500: Loss =  1.5481, Score =  0.7267, lr =  1.0000e-03\n",
      "Epoch  84/500: Loss =  1.5384, Score =  0.7284, lr =  1.0000e-03\n",
      "Epoch  85/500: Loss =  1.5459, Score =  0.7275, lr =  1.0000e-03\n",
      "Epoch  86/500: Loss =  1.5523, Score =  0.7277, lr =  1.0000e-03\n",
      "Epoch  87/500: Loss =  1.5449, Score =  0.7281, lr =  1.0000e-03\n",
      "Epoch  88/500: Loss =  1.5635, Score =  0.7246, lr =  1.0000e-03\n",
      "Epoch  89/500: Loss =  1.5769, Score =  0.7221, lr =  1.0000e-03\n",
      "Epoch  90/500: Loss =  1.5774, Score =  0.7233, lr =  1.0000e-03\n",
      "Epoch  91/500: Loss =  1.5828, Score =  0.7232, lr =  1.0000e-03\n",
      "Epoch  92/500: Loss =  1.5580, Score =  0.7264, lr =  1.0000e-03\n",
      "Epoch  93/500: Loss =  1.5410, Score =  0.7271, lr =  1.0000e-03\n",
      "Epoch  94/500: Loss =  1.5298, Score =  0.7289, lr =  1.0000e-03\n",
      "Epoch  95/500: Loss =  1.5393, Score =  0.7286, lr =  1.0000e-03\n",
      "Epoch  96/500: Loss =  1.5219, Score =  0.7310, lr =  1.0000e-03\n",
      "Epoch  97/500: Loss =  1.5108, Score =  0.7324, lr =  1.0000e-03\n",
      "Epoch  98/500: Loss =  1.5241, Score =  0.7306, lr =  1.0000e-03\n",
      "Epoch  99/500: Loss =  1.5308, Score =  0.7291, lr =  1.0000e-03\n",
      "Epoch 100/500: Loss =  1.5403, Score =  0.7278, lr =  1.0000e-03\n",
      "Epoch 101/500: Loss =  1.5524, Score =  0.7252, lr =  1.0000e-03\n",
      "Epoch 102/500: Loss =  1.5484, Score =  0.7277, lr =  1.0000e-03\n",
      "Epoch 103/500: Loss =  1.5373, Score =  0.7298, lr =  1.0000e-03\n",
      "Epoch 104/500: Loss =  1.5471, Score =  0.7277, lr =  1.0000e-03\n",
      "Epoch 105/500: Loss =  1.5402, Score =  0.7292, lr =  1.0000e-03\n",
      "Epoch 106/500: Loss =  1.5369, Score =  0.7300, lr =  1.0000e-03\n",
      "Epoch 107/500: Loss =  1.5198, Score =  0.7325, lr =  1.0000e-03\n",
      "Epoch 108/500: Loss =  1.5450, Score =  0.7287, lr =  1.0000e-03\n",
      "Epoch 109/500: Loss =  1.5569, Score =  0.7275, lr =  1.0000e-03\n",
      "Epoch 110/500: Loss =  1.5514, Score =  0.7286, lr =  1.0000e-03\n",
      "Epoch 111/500: Loss =  1.5581, Score =  0.7271, lr =  1.0000e-03\n",
      "Epoch 112/500: Loss =  1.5512, Score =  0.7286, lr =  1.0000e-03\n",
      "Epoch 113/500: Loss =  1.5539, Score =  0.7275, lr =  1.0000e-03\n",
      "Epoch 114/500: Loss =  1.5647, Score =  0.7271, lr =  1.0000e-03\n",
      "Epoch 115/500: Loss =  1.5455, Score =  0.7296, lr =  1.0000e-03\n",
      "Epoch 116/500: Loss =  1.5376, Score =  0.7305, lr =  1.0000e-03\n",
      "Epoch 117/500: Loss =  1.5319, Score =  0.7310, lr =  1.0000e-03\n",
      "Early stopped.\n",
      "Training complete in 26m 3s\n",
      "Best val Acc: 0.732532\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEICAYAAAC3Y/QeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAoNklEQVR4nO3dd3yV5f3/8dcnCVmMsFfCVJAlCEQRrVsqTtQ6qFrtUmlr19cua/v9dn2tLf222p9W6rZLHFVLFbd1gsiQvXcWEFYSyDw5n98f54AhZJxAYsh93s/HIw/Pfd/Xfc51BXyfi+u+7us2d0dEROJLQmtXQEREPn0KfxGROKTwFxGJQwp/EZE4pPAXEYlDCn8RkTik8Je4Y2Znm1luA8cfN7NffZp1ioWZvW1mX42xrJvZ8S1dJ2m7FP7S7Mxss5mVmdm+Gj/3tXa9JMLMrjGzOWZWamZvt3Z9pHUktXYFJLAudfc3WrsSUqfdwD3AMODc1q2KtBb1/OVTZWZfNLP3zex3ZrbHzDaZ2YW1jm80s5LosetrHPuyma2KnveqmQ2occzN7Otmti567i/N7Dgzm2tmxWb2tJkl16rLj81sZ/RfKtdTDzO7xMwWm9neaI95dANlm1QPM7vZzNab2W4zm2VmfWscm2Rmq82sKPovJ6v1WfX+Phri7m+4+9NAfizlJZgU/tIaJgBrgO7Ab4FHLKI98EfgQnfvCJwGLAYws8uBHwNXAj2A94Ana73vZGA8cCrwA+BB4HqgHzAK+HyNsr2jn58J3AQ8aGYn1K6omY0DHgVuBboBfwZmmVlKA+2LqR5mdi7wa+AaoA+wBZgZPdYd+Cfwk2g9NwCn16hXLL8PkXop/KWlvBDtKR/4ubnGsS3u/pC7VwNPEAm+XtFjYWCUmaW5e4G7r4juvxX4tbuvcvcQcBdwUq3e7m/cvTh6znLgNXff6O5FwMvA2Fp1/Km7V7j7O8BLREK4tpuBP7v7PHevdvcngAoiwV6fWOtxPfCouy9y9wrgDmCimQ0ELgJWuvuz7l5FZJhmW43PiOX3IVIvhb+0lMvdvXONn4dqHDsYYu5eGn3Zwd33A9cC04ACM3vJzIZFjw8A7j3wZUJk3NqI9NwP2F7jdVkd2x1qbO+Jft4BW4C+HG4AcHvNLzIiPfi6yja1Hn2jnwuAu+8DdkXb1BfIqXHMa24T2+9DpF4KfzmmuPur7j6JyL8GVgMHvjRygFtrfaGkufucI/yoLtFhpgP6U/cYeA7wv7U+N93dm2OIJZ9IiAMQrU83IA8oIPIlc+CY1dym+X8fEmcU/nLMMLNeZnZZNAQrgH1AdfTwDOAOMxsZLZthZlcf5Uf+3MySzewM4BLgmTrKPARMM7MJB65LmNnFZtbxKD8b4B/Al8zspOg1hLuAee6+mcgw1Egzu9LMkoBvEblOccAR/z7MLNHMUonM9ksws1Qza9cM7ZE2ROEvLeXfdug8/+djOCcBuJ1Ij3g3cBbwdQB3fx74DTDTzIqJjKVfWM/7xGIbsCf6WX8Hprn76tqF3H0BkXH/+6Ll1wNfPIrPrfnebwI/JXJhtwA4DpgaPbYTuBq4m8hQ0BDggxrnHs3v4wtEhp8eAM6Ivn6owTMkcEwPcxERiT/q+YuIxCGFv4hIHFL4i4jEIYW/iEgcOiYXduvevbsPHDiwtashItJmLFy4cKe794i1/DEZ/gMHDmTBggWtXQ0RkTbDzLY0XuoTGvYREYlDCn8RkTik8BcRiUMKfxGROKTwFxGJQwp/EZE4pPAXEYlDCn8RaXPKKqv5z+od7Cgpb9HPcXdeWV7Ax1v3tOjntIZj8iYvEWlZ1WEnFA6TYEa7xLbTB9xYuI/HPtjMC4vzKCkPkdougZsmDuTWs46ja/vkZv2s4vIqfvzcMl5cWkBau0T+fvMExvXv0qyfAZE/i9w9pazfsY+isiquHJfV7J9RF4W/SAAUlVaxIr+Isf27kJacWG+5XfsquP7heazeVgJAenIi9183jnOG9Tys7ANvb+Cp+Vt58MZshvZqjgeXHblw2Hn0g0389tU1GHDRiX246MQ+vLysgIfe28hf5m7h0jF9uG7CAMZkZRB56mX9theX89bqHVw6pi8dUj6JwVB1mFUFJczfvJtHP9hEQVE53zpvCLMW5/Glx+bzzLSJzfK7WLu9hFeXb2Puxl0s2rqH8qowAB1Tk7hibGaj9W8Ox+TDXLKzs13LO4g0rqS8isc+2MxD726kpCJEenIi5w/vxZXjMjlzSA8SEj4JkfKqaq5/eB7L84q4+YzBpCUn8uLSArbs2s9Tt0zkxKwMIDLUce+b67jnjXW0SzS6tk/m2Wmn0a9rOsXlVby1ageDurdnVGYGiTXePxx2du6roCIUpl/X9KNq17LcIma8u4GS8hDd2yezZXcpC7fsYdKIXtx1xYn06JhysOz6HSU8/N4mZi3Jp7SymmG9O3LV+CymnJR5SDmAquowj3+wmXveWMv+ymp6dUrhfy4dyai+Gfxl7maeXpBDcXkIgCE9O/Cbq0Yzrn8XcnaX8rkH5mAG379gGBeM7EWHlCQ+ztnLf1ZHfh8Xj+5DSlIi+ytCvLS0gH0VIc4b3pMB3T55VHR12Jnxzgb+8PpaQmFneJ9OTBjUleF9OnJ8zw4c36MjGelH9kRNM1vo7tkxl1f4i3y6dhSX8+LSAvp2TmN4n47065J+SEjHYm9pJU/M2cJjczaxt7SKz47oxRVjM3l33U5eWV7AntIqBvdoz42nDiB7YFcGdm/PHc8t499L8vnT9eO46MQ+B+tyxZ/mUBEK89CN4ymrrOa1ldt5fM5mrhqfxVc+M4ipD35I5/R2XDq6L0/M3UxJNBw7pSYxtFdHSiurKamoYntxBZWhSA/2jguHcetZx8XcHncnb28ZK/KL+efCXF5buZ2MtHYM7JbOzn2VhN35r0lDuWp8Vr294pLyKl5YnM+zC3NZkrOXpATj2+cN4evnHE9igrEiv4j/emoJa7aXcO6wnlx7cj/ufWMdKwuKAUhKMC4Y1ZsLRvbm5IFd6JORdsj7r9lWwi1/XcCWXaWkJCXQOb0d24srDh7v3iGZicd15+3VOyipCB3cf3zPDgzv04msLmks2rKHeZt2c8noPvzsspF073Dol9PRUPiLtJKq6sgYemIDQb5nfyVXzZjDhsL9B/cN6JbOtLOO44qxmczduIuH3t3ItuJyHvzCeI7v+ckQQ3XYmbdpF7OXFfD8ojz2V1Zz/vCefPPcIYzp1/lgucpQmJeXF/DoB5tZkrP3kM//4eRhfO3sQ0N5/Y4SrvzTnIM9XoDrJvTnV1NGkZBgLNq6hxsenkdpZTWTR/bmy58ZxLbicj5Yt5PNu/bTMTWJDilJ9OqUSlaXNOZs2MXLy7fxk4uH89UzBjf6e5uzYSffmbmYHSWRIO2YksRXzxjMlz8zkI6pR9YLXr+jhHvfXM+/l+Rz+vHdOO247tzzxlq6pCdz1xUncv6IXkBkmOepBTmRP5fx/eidkdrg+7o7i7buZdbiPAr3VXD+8F6cN7wXy3KLeHzOJuZt3M35I3pxw6n96dkxlTdWbeftNYVs3rWf/L1lpCQl8rPLRvK5cc0/tKPwF/mU5ewu5bEPNvPU/K0kJyXwmSE9OH94Ty4d3feQHn1pZYjrHprHyoJiHroxm4y0dqzML2bm/K0szS0iJSmBilCY3p1SCYXDhMLOY188mcE9OvDEnM38Ze4Wdu6rILVdAheO6sOtZw1mWO9ODdZt/Y4S1m7fx6ad++nWPplrT+5XZ+hsKNzHwi17yOqSxoBu7cnsnHbY+wCHfBnVJ1Qd5lszP2b2sm3cceEwbjlzcL1B9/KyAr49czEDuqVz42kDGdm3E8N7d2rwukWs3J2nF+Tw3/9aQUUozAUje/HrK0c3+4XhWFWHneqwk5zUMhfYFf4in4LI8Mg2Xvg4j3fWFpJgxsWj+5CUkMA7awvZua+Cm88YxJ0XjwAi4+23/HUh768r5IEbxnPByN4H38vdeX/9TmYtzufUwd24dExfCorK+MIjH1FYUkFSglFSEeLcYT353LgszhnWg/TkY3uuRlV1mG9HvwDOHdaT33xuNMmJCbyyooBFW/aSnJRAKBxm5vwcxvXvwiM3ZdM5vWVCef2OfWws3MekEb0+lQuprUXhL9IAd+eNVTt44O31TDyuG9/77AkHA+E/q3ewc18FV2f3O1h+174KZi8r4OLRfenaPhl356n5Ofzv7FWUlIfok5HKFWMz+cLEAQfHiMNh5+f/XsETc7fwyykjuXh0X776xHw+ztnL3VeeyLUn94+proUlFXx75sd0aZ/MN84+nhF9G+7lH2vCYecvczfz65dXk5yUQEVVmMrqMF2iFzTLq8KcfUIPfn/NSc3S0493Cn+ReqzML+aO55ayJLeIjLR2FJVV8f0LTuAb5xzP8x/ncvvTS3DgpW+ecTBov/H3Rby0rID05ES+MHEAqwpKeHdtIacO7sq3zxvKhEFd67xYWx12bv3rAt5avYM+GWns3FfBPdeexIXRC63xZN32Ev7vtbVkdknjsjF9GR3DVExpOoW/NLvSyhBvrynkgpG9G7yYeSzL21vG5fd/gAHf++wJXD42k+8/u4R/Lc7nyrGZPL84j1MHdWP1tmKG9+nE3786gXmbdjP1wQ+5fkJ/SspDvLg0n5SkRO64aBg3TBjQ6Ayd0soQ1/75Q3L2lPLwjdlkD+z66TRW4lJTw//YHjiUY8IfXl/LQ+9t4sqxmUy/ekzMXwDhsDd5CuMBj76/icfnbObWswZzTXa/mO9CLSqt4pmFOTz50VY6pLbjzouGM6JvJ77y+HzKK6t57uunMSR6k870q8awt7SK5z7O44wh3Xnoxmyemp/D/8xawesrt/OHN9aR2TmNn1w8grTkRH544TCSExMOmzten/TkJJ792kQqQmE6HeGsFZGWop5/nCqrrOY3r6xmTL8Mrhhb/+3kRaVVnHb3m3ROTyZvbxlXjstk+lUNfwHsqwjx21dW89T8HJ6+deIh0xBjsXZ7CZf88X3SkhMpKqtiYLd0vn7O8Vw2pi+p7eofG35paQG3P7OY8qow4wd0oWBvGflF5WR2TmNbcTmPffFkzhx66POtD1y4vWBkb1LbJVJVHeaCe94lf28Z5VVh7r9uHBePjr+hGml71POXw+yrCPHj55YxOiuDa07ux/6KEDf/ZQHL84pJTkpgVN+Mg73h2v42bwv7K6t5Zlo2b6zazu9fX8vCLXvomJpEu8QEjuvRgdFZGQzs1p7SymoK91XwwH/WU1BcTlKC8fd5W5oU/qHqMN9/ZgkdUpN47btnsiRnL9NfXcMPnl3KXbNXccnoPuyvqGbjzv307JjCL6aMpE9GGnM27OS7Ty3mxKwMfjFlJCP7ZlBWWc0D72zgsfc38cspow4LfoC05ESmnJR5cLtdYgJ3XjScrzyxgFMGdeWiE3sfdo5IEKjnHwd++eJKHnl/EwAdUpIOzif/2WUjuWv2KrK6pPHc104jqdbQSnlVNZ/5zVuM6JvBX758CgB/+3AL76wtJBx2yqqqWbOthF37Kw85b2ivDtz9udHM/GgrLy0tYP5Pzo95auKMdzZw98urue+6sVwyui8QmaEzd+Mu/jp3C2+s2k6PDikM6NaeJbmRKYPfOncIf3h9Lb0zUnl22mmH3R7v7k26wOjuvLA4j1MHdzvsLk+RY5V6/nKIlfnFPD5nM9dN6M/Uk/vx8Hub2LxrP7+7egxDe3UkrV0i3/jHIma8s4Grs/vx8da9lFdVM35Al+h89UqmnfXJXZo3nDqAG04dcHDb3ckvKidvTxntUxLpkJJEVpd0EhOM6rDz9IJcZi/bxlXjsw45Z8uuUlZvK6ZLejI9O6WybnsJ/1qcz6srtnHhqN5cXGNWjJlx2nHdOe247ocE+cbCfXzzyY/5xYsr6d0plSe+fEqd66I0dWaJmTU4FCYSBOr5B1g47Fz957ls2rmft24/q96baG77xyJeXFpw2H4zGJ2ZwQvfOP2Ipua5O+f+3zv07JjCU7dOpCJUzfRX1vDy8m3k7S07rHy39slcMroP3500NOYbfipC1Tw5bytnDO3BcT06NLmOIkGhnr8c9MzCHBZu2cP0q0Y3GKa/unwU3Tuk0L9rOmP6dSatXSILt+5hSc5ePn9K/yOek21mXDU+i+mvrmH1tmL+96VVvLduJ5NG9GLaWYMZndWZ4vLIgmA9OqZw2nHdmry2fEpSIl88fdAR1U8knqnnH1DLcou45s9zOTErg6duObXVbqopKCrj9LvfIj05idLKEHdfOZprTu7X+Iki0iRN7fm3nUf4SMzy95bxlSfm07V9MvddN7ZV76bsk5HGmUN7UF5VzR8/P1bBL3KM0LBPwGwvLucrTyygtLKaf35tAj07NrxE7afh99ecxO79lRzfU2PyIscKhX8bV1RaxfaScnJ2l/LcojxeXbENgEe+eDIn9G7dR+8d0LV9cqstoysidYsp/M1sMnAvkAg87O531zr+feD6Gu85HOjh7rsbO1eOTEFRGT94dinvrdt5cF+n1CS+eNpAbjh1AAO7t2/gbBGJd42Gv5klAvcDk4BcYL6ZzXL3lQfKuPt0YHq0/KXAd6PB3+i50jSVoTCvrNjGT19YTlV1mO+cP4TBPTrQq2MKo7M6a2lcEYlJLD3/U4D17r4RwMxmAlOA+gL888CTR3huYBWWVLC9uJxRmRlNOi8cdhZu3cOsxfks2LKH9TtKqKp2xvTrzD3XnsQg9fBF5AjEEv6ZQE6N7VxgQl0FzSwdmAzc1tRzgyxUHebGRz9iw459zP72GTFf+Jy7YRffe2YJeXvLSG2XwMkDu3LW0MGMzspg0oheTZ4TLyJyQCzhX9c8wfpuDrgU+MDddzf1XDO7BbgFoH//2J501FY89sFmVhVEFlG78/llzIxh3n1pZYjvPbOEpETjD9eO4bMjetM+RdfnRaR5xNJ1zAVqTs7OAvLrKTuVT4Z8mnSuuz/o7tnunt2jx+GrL7ZVuXtK+f3razl/eE9+dulI5m3azTMLcxs9794315G3t4zfXT2GK8ZmKfhFpFnFkijzgSFmNgjIIxLw19UuZGYZwFnADU09N6jcnf/51wrM4OdTRtGnUyrPLcrlrtmr6NExhbLKatKSEzl7aI9D/iWwZlsJj7y3iavHZ3Gynv4kIi2g0fB395CZ3Qa8SmS65qPuvsLMpkWPz4gWvQJ4zd33N3ZuczfiWPXO2kLeXL2DOy8aTmbnyNLAd115Ihf/8T2+9Nj8g+V+MWUkN04cCESe/frTF5bTITWJOy4a3hrVFpE4oLV9Woi7c/mf5rBrXwVv3X42yUmfjLCtKiimqKyKzuntuPvl1czdsItZt32Gob068OPnl/HkRzn89qrRXJOtpRBEJDZa1fMY8fbaQpbk7OXuK088JPgBhvfpdPD19KvGcOG97/KtJz9m4nHdePKjHG4753gFv4i0KM0VbAHuzj2vryWrSxpXjmv4oSA9OqYw/aoxrNlewuNzNvOl0wdy+2eHfko1FZF4pZ5/M1mweTf/XpLPmH6dcYcluUV19vrrcs6wntx50XBKyqv47qShrboKp4jEB4V/M3h1xTa++eTHVIedJ+ZuASCrSxqfGx/7owBvPnNw44VERJqJwv8oPTV/K3c8t4wx/TrzyE0nk7+3jA837mLcgC66A1dEjlkK/yNUVR3m7pdX88j7mzhzaA9m3DCO9OQkurZPbvL6PSIinzaF/xEoLKngtn8sYt6m3dw0cQB3XjwiprF9EZFjhcL/CPz4+WUsyd3LH66NLL0gItLWqLvaRO7Ogs27mTImU8EvIm2Wwr+J8vaWsae0ilGZnRovLCJyjFL4N9HyvCIAXdQVkTZN4d9Ey/OKSUywQ5ZoEBFpaxT+TbQsr4ghPTuQ2k7PyhWRtkvh3wTuzvK8Ig35iEibp/BvgoKicnbtr+REhb+ItHEK/ybQxV4RCQqFfxMszysiwWCELvaKSBun8G+CZXlFHN+zA2nJutgrIm2bwr8JlucXa8hHRAJB4R+j7cXlFJZU6GKviASCFnZrxNPzc3hnbSGrthUDutgrIsGg8G/Ahxt38YN/LiWzcxon9O7IJSf2YWy/zq1dLRGRo6bwr0c47PzqpZX0zUjlzdvP0h29IhIoGvOPKi6v4sONu6gIVQPwwuI8lucV8/3JJyj4RSRw4r7n/9bq7Tz2wWY+3LiLqmqnX9c0bp90AtNfXcPorAymjMls7SqKiDS7uA7/nN2lTPvbInp2TOHLpw9iWJ+O/PmdjXznqcUA3Dt1LAkJ1rqVFBFpAXEd/ne/vJpEM56ddhq9M1IBuGxMJv9clMu+8hCnDOrayjUUEWkZcRv+H23azUvLCvju+UMPBj9AYoJxTXa/VqyZiEjLi8sLvuGw84sXV9AnI5Vbzhzc2tUREfnUxRT+ZjbZzNaY2Xoz+1E9Zc42s8VmtsLM3qmxf7OZLYseW9BcFT8aLy4rYHleMT+cPEzr9IhIXGp02MfMEoH7gUlALjDfzGa5+8oaZToDfwImu/tWM+tZ623OcfedzVfto/P2mh10a5/MZWP6tnZVRERaRSw9/1OA9e6+0d0rgZnAlFplrgOec/etAO6+o3mr2bwWbdnD+AFdNJNHROJWLOGfCeTU2M6N7qtpKNDFzN42s4VmdmONYw68Ft1/S30fYma3mNkCM1tQWFgYa/2bbOe+CjbvKmX8gC4t9hkiIse6WGb71NU99jreZzxwHpAGzDWzD919LXC6u+dHh4JeN7PV7v7uYW/o/iDwIEB2dnbt9282C7fsASB7oMJfROJXLD3/XKDm3McsIL+OMq+4+/7o2P67wBgAd8+P/ncH8DyRYaRWs2jLHpITExjZV6tzikj8iiX85wNDzGyQmSUDU4FZtcr8CzjDzJLMLB2YAKwys/Zm1hHAzNoDnwWWN1/1m27hlj2Myuyk9XpEJK41Ouzj7iEzuw14FUgEHnX3FWY2LXp8hruvMrNXgKVAGHjY3Zeb2WDgeTM78Fn/cPdXWqoxjakIVbM0r4ibJg5orSqIiBwTYrrD191nA7Nr7ZtRa3s6ML3Wvo1Eh3+OBcvziqkMhRk/QMs2iEh8i6s7fBdFL/aOG9C5dSsiItLK4ir8F27ZQ/+u6fTsmNp4YRGRAIub8Hd3Fm7do/n9IiLEUfi/v34nhSUVTNAyzSIi8RH+VdVhfvHvlfTvms7lY/VkLhGRuAj/v324hXU79vGTi4drfr+ICHEQ/rv3V/KH19dyxpDuTBrRq7WrIyJyTAh8+N/31nr2V1bz35eMIHqzmYhI3At8+K/IL2Jc/84M6dWxtasiInLMCHz4F5eHyEhLbu1qiIgcU4If/mVVZKS1a+1qiIgcU4If/uVVdEqLaQkjEZG4EejwD4edfRUhOqWq5y8iUlOgw7+kPIQ7dNKwj4jIIQId/sXlVQB0StWwj4hITYEO/6KyaPir5y8icohAh/8nPX+Fv4hITcEO/7IQgGb7iIjUEuzwj/b8Nc9fRORQwQ5/jfmLiNQp8OFvBh2SNewjIlJTsMO/PETHlCQSErSap4hITcEO/7IqDfmIiNQh2OFfXqVpniIidQh2+JeFNM1TRKQOwQ5/9fxFROoU7PDXWv4iInUKdPgX6YKviEidYgp/M5tsZmvMbL2Z/aieMmeb2WIzW2Fm7zTl3JYQqg6zv7Jawz4iInVo9GqomSUC9wOTgFxgvpnNcveVNcp0Bv4ETHb3rWbWM9ZzW0pJudb1ERGpTyw9/1OA9e6+0d0rgZnAlFplrgOec/etAO6+ownntgit6CkiUr9Ywj8TyKmxnRvdV9NQoIuZvW1mC83sxiacC4CZ3WJmC8xsQWFhYWy1b8AnK3oq/EVEaotlTKSutRG8jvcZD5wHpAFzzezDGM+N7HR/EHgQIDs7u84yTaGneImI1C+WZMwF+tXYzgLy6yiz0933A/vN7F1gTIzntgit6CkiUr9Yhn3mA0PMbJCZJQNTgVm1yvwLOMPMkswsHZgArIrx3BZxsOev8BcROUyjPX93D5nZbcCrQCLwqLuvMLNp0eMz3H2Vmb0CLAXCwMPuvhygrnNbqC2HOPD8Xt3kJSJyuJgGxN19NjC71r4ZtbanA9NjOffTUFwWIsGgfXLip/3RIiLHvMDe4VtcHrm710xr+YuI1Bbc8C/Tom4iIvUJbviXazlnEZH6BDf81fMXEalXcMNfa/mLiNQrsOEfWc5Zwz4iInUJbPgXl4U0x19EpB6BDP/KUJiyKq3lLyJSn0CGf4mWdhARaVAgw79YD3IREWlQMMO/TA9yERFpSDDDX8M+IiINCmb4R5/i1VEPchERqVMgw7+8qhqAtHZa0VNEpC6BDP+KUBiAlCSFv4hIXQIZ/gd6/qntAtk8EZGjFsh0VM9fRKRhAQ3/SM8/JSmQzRMROWqBTMfyqjDJiQkkJOgpXiIidQlk+FeEqtXrFxFpQCATsiIUJkXTPEVE6hXI8C+vUs9fRKQhgUzISM8/kE0TEWkWgUzIiqpqUjXNU0SkXsEMf/X8RUQaFMiErKgKa8xfRKQBgUzI8lA1qZrtIyJSr0CGv3r+IiINC2RCRm7yUs9fRKQ+MYW/mU02szVmtt7MflTH8bPNrMjMFkd//rvGsc1mtiy6f0FzVr4+5VVhregpItKARh91ZWaJwP3AJCAXmG9ms9x9Za2i77n7JfW8zTnuvvPoqho79fxFRBoWS/f4FGC9u29090pgJjClZat1dCpC6vmLiDQkloTMBHJqbOdG99U20cyWmNnLZjayxn4HXjOzhWZ2S30fYma3mNkCM1tQWFgYU+Xr4u7R5R3U8xcRqU8sTziva11kr7W9CBjg7vvM7CLgBWBI9Njp7p5vZj2B181stbu/e9gbuj8IPAiQnZ1d+/1jFgo7Ydda/iIiDYklIXOBfjW2s4D8mgXcvdjd90VfzwbamVn36HZ+9L87gOeJDCO1mANP8dI8fxGR+sUS/vOBIWY2yMySganArJoFzKy3mVn09SnR991lZu3NrGN0f3vgs8Dy5mxAbQee36vlHURE6tfosI+7h8zsNuBVIBF41N1XmNm06PEZwFXA18wsBJQBU93dzawX8Hz0eyEJ+Ie7v9JCbQFqPr9X4S8iUp9YxvwPDOXMrrVvRo3X9wH31XHeRmDMUdaxSQ70/DXsIyJSv8B1jyuq1PMXEWlM4BKyIhQd89dUTxGRegUu/MsP9Px1wVdEpF6BS0j1/EVEGhfA8NeYv4hIYwKXkJrtIyLSuMCFv3r+IiKNC1xCankHEZHGBS/8tbyDiEijApeQGvYREWlc4BKyoqoaM0hODFzTRESaTeASsjwUJiUpgehiciIiUofAhX+FnuIlItKowIV/eZWe3ysi0pjApWRFSD1/EZHGBDD8w5rpIyLSiMClZHlVtW7wEhFpRODCXz1/EZHGBS4lK0Jh3d0rItKIwKVkeVU1qbrgKyLSoMCFv3r+IiKNC1xKVoTU8xcRaUzgwr+8Sj1/EZHGBC4ltbyDiEjjghf+GvMXEWlUoFLS3aPz/NXzFxFpSKDCXw9yERGJTaBSsqJKz+8VEYlFTOFvZpPNbI2ZrTezH9Vx/GwzKzKzxdGf/4713OZUEYo+v1c9fxGRBiU1VsDMEoH7gUlALjDfzGa5+8paRd9z90uO8NxmoWEfEZHYxJKSpwDr3X2ju1cCM4EpMb7/0ZzbZOVVkZ6/hn1ERBoWS/hnAjk1tnOj+2qbaGZLzOxlMxvZxHMxs1vMbIGZLSgsLIyhWodTz19EJDaxpGRdT0L3WtuLgAHuPgb4f8ALTTg3stP9QXfPdvfsHj16xFCtwx0c81fPX0SkQbGEfy7Qr8Z2FpBfs4C7F7v7vujr2UA7M+sey7nNqfzAbB/1/EVEGhRLSs4HhpjZIDNLBqYCs2oWMLPeZmbR16dE33dXLOc2J/X8RURi0+hsH3cPmdltwKtAIvCou68ws2nR4zOAq4CvmVkIKAOmursDdZ7bQm2pMc9fPX8RkYY0Gv5wcChndq19M2q8vg+4L9ZzW0r5wXn+6vmLiDQkUF3kAz1/zfYREWlYoFLywFRPzfMXEWlYoML/wE1e6vmLiDQsUCmpm7xERGITqJQsr6omKcFISgxUs0REml2gUjLyIJdANUlEpEUEKikrQtW6wUtEJAaBCv/yqrCWdhARiUGgkjLy8Hb1/EVEGhOs8K+q1pi/iEgMApWU5er5i4jEJFDhr56/iEhsApWUFaGwlnYQEYlBoMK/XD1/EZGYBCopK3WTl4hITAKVlBr2ERGJTaDCX8M+IiKxCVRSRtb2Uc9fRKQxgQr/84f3ZFRmp9auhojIMS+mZ/i2FfdMHdvaVRARaRMC1fMXEZHYKPxFROKQwl9EJA4p/EVE4pDCX0QkDin8RUTikMJfRCQOKfxFROKQuXtr1+EwZlYIbDnC07sDO5uxOq0taO2B4LUpaO2B4LUpaO2Bw9s0wN17xHryMRn+R8PMFrh7dmvXo7kErT0QvDYFrT0QvDYFrT1w9G3SsI+ISBxS+IuIxKEghv+DrV2BZha09kDw2hS09kDw2hS09sBRtilwY/4iItK4IPb8RUSkEQp/EZE4FJjwN7PJZrbGzNab2Y9auz5Hwsz6mdl/zGyVma0ws29H93c1s9fNbF30v11au65NYWaJZvaxmb0Y3W7r7elsZs+a2eron9XEttwmM/tu9O/bcjN70sxS21p7zOxRM9thZstr7Ku3DWZ2RzQr1pjZBa1T6/rV057p0b9zS83seTPrXONYk9sTiPA3s0TgfuBCYATweTMb0bq1OiIh4HZ3Hw6cCnwj2o4fAW+6+xDgzeh2W/JtYFWN7bbennuBV9x9GDCGSNvaZJvMLBP4FpDt7qOARGAqba89jwOTa+2rsw3R/6emAiOj5/wpmiHHksc5vD2vA6PcfTSwFrgDjrw9gQh/4BRgvbtvdPdKYCYwpZXr1GTuXuDui6KvS4iESiaRtjwRLfYEcHmrVPAImFkWcDHwcI3dbbk9nYAzgUcA3L3S3ffShttE5HGuaWaWBKQD+bSx9rj7u8DuWrvra8MUYKa7V7j7JmA9kQw5ZtTVHnd/zd1D0c0Pgazo6yNqT1DCPxPIqbGdG93XZpnZQGAsMA/o5e4FEPmCAHq2YtWa6h7gB0C4xr623J7BQCHwWHQo62Eza08bbZO75wG/A7YCBUCRu79GG21PLfW1IQh58WXg5ejrI2pPUMLf6tjXZuewmlkH4J/Ad9y9uLXrc6TM7BJgh7svbO26NKMkYBzwgLuPBfZz7A+J1Cs6Dj4FGAT0Bdqb2Q2tW6sW16bzwszuJDJE/PcDu+oo1mh7ghL+uUC/GttZRP7p2uaYWTsiwf93d38uunu7mfWJHu8D7Git+jXR6cBlZraZyFDcuWb2N9pueyDydy3X3edFt58l8mXQVtt0PrDJ3QvdvQp4DjiNttuemuprQ5vNCzO7CbgEuN4/uUnriNoTlPCfDwwxs0Fmlkzk4sesVq5Tk5mZERlLXuXuv69xaBZwU/T1TcC/Pu26HQl3v8Pds9x9IJE/k7fc/QbaaHsA3H0bkGNmJ0R3nQespO22aStwqpmlR//+nUfkWlNbbU9N9bVhFjDVzFLMbBAwBPioFerXJGY2GfghcJm7l9Y4dGTtcfdA/AAXEbkCvgG4s7Xrc4Rt+AyRf64tBRZHfy4CuhGZrbAu+t+urV3XI2jb2cCL0ddtuj3AScCC6J/TC0CXttwm4OfAamA58Fcgpa21B3iSyDWLKiI94a801AbgzmhWrAEubO36x9ie9UTG9g9kw4yjaY+WdxARiUNBGfYREZEmUPiLiMQhhb+ISBxS+IuIxCGFv4hIHFL4i4jEIYW/iEgc+v8QUA/vGp6jTAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/500: Loss =  2.6329, Score =  0.5406, lr =  1.0000e-03\n",
      "Epoch   2/500: Loss =  2.2367, Score =  0.6086, lr =  1.0000e-03\n",
      "Epoch   3/500: Loss =  2.0152, Score =  0.6441, lr =  1.0000e-03\n",
      "Epoch   4/500: Loss =  1.9652, Score =  0.6533, lr =  1.0000e-03\n",
      "Epoch   5/500: Loss =  1.9924, Score =  0.6474, lr =  1.0000e-03\n",
      "Epoch   6/500: Loss =  1.8715, Score =  0.6674, lr =  1.0000e-03\n",
      "Epoch   7/500: Loss =  1.7748, Score =  0.6869, lr =  1.0000e-03\n",
      "Epoch   8/500: Loss =  1.7955, Score =  0.6851, lr =  1.0000e-03\n",
      "Epoch   9/500: Loss =  1.7766, Score =  0.6873, lr =  1.0000e-03\n",
      "Epoch  10/500: Loss =  1.8431, Score =  0.6749, lr =  1.0000e-03\n",
      "Epoch  11/500: Loss =  1.7421, Score =  0.6912, lr =  1.0000e-03\n",
      "Epoch  12/500: Loss =  1.7390, Score =  0.6902, lr =  1.0000e-03\n",
      "Epoch  13/500: Loss =  1.7727, Score =  0.6832, lr =  1.0000e-03\n",
      "Epoch  14/500: Loss =  1.7189, Score =  0.6918, lr =  1.0000e-03\n",
      "Epoch  15/500: Loss =  1.6685, Score =  0.7013, lr =  1.0000e-03\n",
      "Epoch  16/500: Loss =  1.6604, Score =  0.7033, lr =  1.0000e-03\n",
      "Epoch  17/500: Loss =  1.6582, Score =  0.7004, lr =  1.0000e-03\n",
      "Epoch  18/500: Loss =  1.6776, Score =  0.6984, lr =  1.0000e-03\n",
      "Epoch  19/500: Loss =  1.6614, Score =  0.7027, lr =  1.0000e-03\n",
      "Epoch  20/500: Loss =  1.6620, Score =  0.7026, lr =  1.0000e-03\n",
      "Epoch  21/500: Loss =  1.6550, Score =  0.7028, lr =  1.0000e-03\n",
      "Epoch  22/500: Loss =  1.6770, Score =  0.6988, lr =  1.0000e-03\n",
      "Epoch  23/500: Loss =  1.6873, Score =  0.6981, lr =  1.0000e-03\n",
      "Epoch  24/500: Loss =  1.6580, Score =  0.7019, lr =  1.0000e-03\n",
      "Epoch  25/500: Loss =  1.6236, Score =  0.7098, lr =  1.0000e-03\n",
      "Epoch  26/500: Loss =  1.6826, Score =  0.6977, lr =  1.0000e-03\n",
      "Epoch  27/500: Loss =  1.6322, Score =  0.7077, lr =  1.0000e-03\n",
      "Epoch  28/500: Loss =  1.6065, Score =  0.7113, lr =  1.0000e-03\n",
      "Epoch  29/500: Loss =  1.6718, Score =  0.6985, lr =  1.0000e-03\n",
      "Epoch  30/500: Loss =  1.6403, Score =  0.7027, lr =  1.0000e-03\n",
      "Epoch  31/500: Loss =  1.6601, Score =  0.7009, lr =  1.0000e-03\n",
      "Epoch  32/500: Loss =  1.6553, Score =  0.7010, lr =  1.0000e-03\n",
      "Epoch  33/500: Loss =  1.6779, Score =  0.6986, lr =  1.0000e-03\n",
      "Epoch  34/500: Loss =  1.6859, Score =  0.6973, lr =  1.0000e-03\n",
      "Epoch  35/500: Loss =  1.7105, Score =  0.6921, lr =  1.0000e-03\n",
      "Epoch  36/500: Loss =  1.6841, Score =  0.6979, lr =  1.0000e-03\n",
      "Epoch  37/500: Loss =  1.6857, Score =  0.6979, lr =  1.0000e-03\n",
      "Epoch  38/500: Loss =  1.6641, Score =  0.7025, lr =  1.0000e-03\n",
      "Epoch  39/500: Loss =  1.6632, Score =  0.7017, lr =  1.0000e-03\n",
      "Epoch  40/500: Loss =  1.6545, Score =  0.7037, lr =  1.0000e-03\n",
      "Epoch  41/500: Loss =  1.6508, Score =  0.7036, lr =  1.0000e-03\n",
      "Epoch  42/500: Loss =  1.6608, Score =  0.7020, lr =  1.0000e-03\n",
      "Epoch  43/500: Loss =  1.6111, Score =  0.7107, lr =  1.0000e-03\n",
      "Epoch  44/500: Loss =  1.6189, Score =  0.7094, lr =  1.0000e-03\n",
      "Epoch  45/500: Loss =  1.6184, Score =  0.7099, lr =  1.0000e-03\n",
      "Epoch  46/500: Loss =  1.6161, Score =  0.7089, lr =  1.0000e-03\n",
      "Epoch  47/500: Loss =  1.6208, Score =  0.7087, lr =  1.0000e-03\n",
      "Epoch  48/500: Loss =  1.6109, Score =  0.7105, lr =  1.0000e-03\n",
      "Early stopped.\n",
      "Training complete in 10m 51s\n",
      "Best val Acc: 0.711255\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/500: Loss =  4.7257, Score =  0.2298, lr =  1.0000e-03\n",
      "Epoch   2/500: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     88\u001b[0m criterion \u001b[38;5;241m=\u001b[39m get_criterion(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Train and evaluate fine tuned model\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m model, hist, lrs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloaders_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs_ft\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Plot learning curve\u001b[39;00m\n\u001b[0;32m     94\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(hist)\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloaders, criterion, optimizer, num_epochs, is_inception)\u001b[0m\n\u001b[0;32m     32\u001b[0m running_r2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Iterate over data.\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m dataloaders[phase]:\n\u001b[0;32m     36\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     37\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mC:\\tools\\miniconda3\\envs\\ml\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mC:\\tools\\miniconda3\\envs\\ml\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    691\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 692\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    694\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mC:\\tools\\miniconda3\\envs\\ml\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mC:\\tools\\miniconda3\\envs\\ml\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mRocksData.__getitem__\u001b[1;34m(self, ix)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, ix):\n\u001b[0;32m    116\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[ix,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 117\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m     img \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mfromarray(img)  \n\u001b[0;32m    119\u001b[0m     label \u001b[38;5;241m=\u001b[39m deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[ix,\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mtolist())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#lr_ft = 5e-4 # override previously defined lr for finetuning\n",
    "\n",
    "new_im_each_epoch = False # False means using the same intermediate model for all ensemble models\n",
    "\n",
    "\n",
    "for e in range(1, n_ensemble + 1):\n",
    "    \n",
    "       \n",
    "    # each epoch a new intermediate model?\n",
    "    if new_im_each_epoch:\n",
    "\n",
    "        # Intermediate model\n",
    "        model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        set_parameter_requires_grad(model, feature_extract_im)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        new_layers = OutputLayers(n_layers, num_ftrs, n_dense, dropout)\n",
    "        model.fc = new_layers # replace last layer\n",
    "\n",
    "        # Send the model to GPU\n",
    "        model = model.to(device)\n",
    "\n",
    "        # create datalaoders with specific batch size\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size_im)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size_im)\n",
    "        dataloaders_dict = {\"train\":train_loader,\"val\":val_loader}\n",
    "\n",
    "        # Create Optimizer and define params to update\n",
    "        params_to_update = model.parameters()\n",
    "        if feature_extract_im:\n",
    "            params_to_update = []\n",
    "            for name,param in model.named_parameters():\n",
    "                if param.requires_grad == True:\n",
    "                    params_to_update.append(param)\n",
    "                    #print(\"\\t\",name)\n",
    "\n",
    "        else:\n",
    "            for name,param in model.named_parameters():\n",
    "                if param.requires_grad == True:\n",
    "                    #print(\"\\t\",name)\n",
    "                    ...\n",
    "\n",
    "        # Instantiate optimizer for intermediate model\n",
    "        optimizer = optim.Adam(params_to_update, lr=lr_im)\n",
    "\n",
    "        # Setup the loss fxn\n",
    "        criterion = get_criterion('L2')\n",
    "\n",
    "        # Initial training and evaluate\n",
    "        model, hist, lrs = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs_im)\n",
    "\n",
    "        # Plot learning curve\n",
    "        plt.plot(hist)\n",
    "        plt.title(f'Intermediate model {e}')\n",
    "        plt.show()\n",
    "\n",
    "        # Save intermediate model\n",
    "        torch.save(model.state_dict(), PATH_IM)\n",
    "        \n",
    "    else:\n",
    "        model = load_pretrained_model()\n",
    "\n",
    "    # fine tuning\n",
    "    \n",
    "    # create dataloaders with specific batch size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size_ft)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size_ft)\n",
    "    dataloaders_dict = {\"train\":train_loader,\"val\":val_loader}\n",
    "            \n",
    "    # Create Optimizer and define params to update\n",
    "    params_to_update = model.parameters()\n",
    "    if feature_extract_ft:\n",
    "        params_to_update = []\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "                #print(\"\\t\",name)\n",
    "    else:\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                #print(\"\\t\",name)\n",
    "                ...\n",
    "\n",
    "    # Instantiate optimizer for finetuning\n",
    "    # optimizer = optim.SGD(params_to_update, lr=lr_ft, momentum=0.9)\n",
    "    optimizer = optim.Adagrad(params_to_update, lr=lr_ft)\n",
    "   \n",
    "    # Setup the loss fxn\n",
    "    criterion = get_criterion(\"L2\")\n",
    "\n",
    "    # Train and evaluate fine tuned model\n",
    "    model, hist, lrs = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs_ft)\n",
    "    \n",
    "    # Plot learning curve\n",
    "    plt.plot(hist)\n",
    "    plt.title(f'Ensemble model {e}')\n",
    "    plt.show()\n",
    "    \n",
    "    # Save intermediate model\n",
    "    PATH_EN = f'CNN_checkpoints/state_dict_ensemble_model_{e}.pt'\n",
    "    torch.save(model.state_dict(), PATH_EN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load checkpoints and get predictions for validation and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataloaders for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_loader = DataLoader(pred_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run ensemble models (CNNs) ...\n",
    "... to collect their individual predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = []\n",
    "rocks_120_pred = []\n",
    "n_ensemble = 1\n",
    "for e in range(n_ensemble):\n",
    "    model = load_pretrained_model(e)\n",
    "    pred = predict(model, test_loader)\n",
    "    test_pred.append(pred)\n",
    "    rocks_120_pred.append(predict(model, pred_loader, unlabeled=True))\n",
    "    \n",
    "\n",
    "test_pred = np.mean(test_pred, 0)\n",
    "rocks_120_pred = np.mean(rocks_120_pred, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rocks_120_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### Run meta learner (LinearRegression, ElasticNet or similar) ...\n",
    "... to find optimally weighted mean of CNN predictions.\n",
    "\n",
    "$Y_{pred} =  b_0 + b_1 Y_{pred_1} + b_2 Y_{pred_2}$\n",
    "\n",
    "<div class=\"alert-warning\">According to their paper Sanders & Nosofsky were not using a meta-learner, they were training an ensemble of 10 models and averaging them.</div><div class=\"alert-warning\">According to their paper Sanders & Nosofsky were not using a meta-learner, they were training an ensemble of 10 models and averaging them.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check model predictions separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_i = 2 # Dimension\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "for e in range(n_ensemble):\n",
    "    Y_pred_dim = test_pred[e][:, d_i-1]\n",
    "    Y_dim = Y_test[:, d_i-1]\n",
    "    corr = np.corrcoef(Y_pred_dim,Y_dim).min()\n",
    "\n",
    "    axs[e].scatter(Y_pred_dim, Y_dim)\n",
    "    axs[e].set_ylabel('observed')\n",
    "    axs[e].set_xlabel('predicted')\n",
    "    axs[e].set_title(f'model {e+1}, dim {d_i}\\n$r$={corr: .2f}')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check stacked model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_i = 2\n",
    "alpha = 0.6161 # 0 we use only model 1, 1 we use only model 2, 0.5 is normal mean\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(10,5))\n",
    "\n",
    "# mean plot\n",
    "Y_pred_dim = np.mean(test_pred, 0)[:, d_i-1]\n",
    "Y_dim = Y_test[:, d_i-1]\n",
    "corr = np.corrcoef(Y_pred_dim,Y_dim).min()\n",
    "\n",
    "axs[0].scatter(Y_pred_dim, Y_dim)\n",
    "axs[0].set_ylabel('observed')\n",
    "axs[0].set_xlabel('predicted')\n",
    "axs[0].set_title(f'stacked model (mean), dim {d_i}\\n$r$={corr: .2f}')\n",
    "\n",
    "# weighted mean plot\n",
    "Y_pred_dim = (test_pred[0]*(1-alpha) + test_pred[1]*alpha)[:, d_i-1]\n",
    "Y_dim = Y_test[:, d_i-1]\n",
    "corr = np.corrcoef(Y_pred_dim,Y_dim).min()\n",
    "\n",
    "axs[1].scatter(Y_pred_dim, Y_dim)\n",
    "axs[1].set_ylabel('observed')\n",
    "axs[1].set_xlabel('predicted')\n",
    "axs[1].set_title(f'stacked model (weighted mean), dim {d_i},\\nalpha={alpha} $r$={corr: .2f}');\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### finding optimal alpha across dimensions ...\n",
    "... using $RÂ²$ score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_space = np.linspace(0,1,100)\n",
    "scores = []\n",
    "for alpha in alpha_space:\n",
    "    preds_1 = test_pred[0, :, :] * (1-alpha)\n",
    "    preds_2 = test_pred[1, :, :] * (alpha)\n",
    "    Y_pred_dim = test_pred[0]*(1-alpha) + test_pred[1]*alpha\n",
    "    Y_dim = Y_test\n",
    "    score = r2_score(Y_dim, Y_pred_dim)\n",
    "    scores.append([alpha, score])\n",
    "scores = np.array(scores)\n",
    "\n",
    "optimal_alpha, max_score = scores[scores.T[1].argmax()]\n",
    "\n",
    "plt.plot(scores[:, 0], scores[:, 1])\n",
    "plt.axvline(optimal_alpha, c='gray', linestyle=':')\n",
    "plt.axhline(max_score, c='gray', linestyle=':')\n",
    "plt.title(rf'optimal $\\alpha$={optimal_alpha:.4f}, max $RÂ²$={max_score:.2f}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplest method: compute mean of all ensemble models\n",
    "#test_prediction = np.mean(test_pred, 0)\n",
    "#rocks_120_prediction = np.mean(rocks_120_pred, 0)\n",
    "\n",
    "# Less simple method: compute weighted mean\n",
    "rocks_120_prediction = (rocks_120_pred[0] * (1-alpha)) + (rocks_120_pred[1] * (alpha))\n",
    "\n",
    "# May best: fitting a linear model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels\n",
    "Y_120 = np.loadtxt(\"../sanders_2018/mds_120.txt\")\n",
    "Y_validate = train.iloc[:, 1:].values\n",
    "Y_test = test.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7799206261926472\n",
      "2.4379886454595114\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(Y_test, test_pred))\n",
    "print(mean_squared_error(Y_120, rocks_120_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get RÂ²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6975700149902655\n",
      "-0.1649851041455579\n"
     ]
    }
   ],
   "source": [
    "print(r2_score(Y_test, test_pred))\n",
    "print(r2_score(Y_120, rocks_120_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save predictions to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"CNN Predictions/MDS Dimensions/cnn_torch_ensemble9_22-07-06_predicted_mds_120.txt\", rocks_120_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
