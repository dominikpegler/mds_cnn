{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit CNN in PyTorch\n",
    "===\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "from skimage import io, transform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import cv2\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 8\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size_im = 90\n",
    "batch_size_ft = 30\n",
    "\n",
    "# Number of epochs to train for \n",
    "num_epochs_im = 10\n",
    "num_epochs_ft = 10\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model, \n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract_im = True\n",
    "feature_extract_ft = False\n",
    "\n",
    "input_size = 224\n",
    "\n",
    "img_dir = \"../finetuning_torchvision_data/360 Rocks\"\n",
    "csv_file = \"../finetuning_torchvision_data/mds_360.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=14, is_inception=False):\n",
    "    \"\"\"\n",
    "    handles the training and validation of a given model. At the end of\n",
    "    training returns the best performing model. After each epoch, the training and validation\n",
    "    accuracies are printed\n",
    "    \"\"\"\n",
    "    \n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_r2 = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        score = r2_score(labels.detach().numpy(), outputs.detach().numpy())\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        global tmp_labels, tmp_outputs\n",
    "                        tmp_labels = labels\n",
    "                        tmp_outputs = outputs\n",
    "                        score = r2_score(labels.detach().numpy(), outputs.detach().numpy())\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics # TODO -> check if this is correct (maybe calculate MSE?)\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_r2 += score\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_r2 / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss: .4f} Acc: {epoch_acc: .4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and best_acc == None:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val' and best_acc < epoch_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "    \n",
    "    # maybe not necessary, but lets check later if it's a handy feature\n",
    "    \n",
    "   #     # save model after each epoch\n",
    "   #     torch.save({\n",
    "   #         'epoch': epoch,\n",
    "   #         'model_state_dict': model.state_dict(),\n",
    "   #         'optimizer_state_dict': optimizer.state_dict(),\n",
    "   #         'loss': loss,\n",
    "   #         ...\n",
    "   #         }, PATH)\n",
    "    \n",
    "        print() # empty line between epochs\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history\n",
    "\n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    \"\"\"\n",
    "    This helper function sets the ``.requires_grad`` attribute of the\n",
    "    parameters in the model to False when we are feature extracting.\n",
    "    \"\"\"\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    else:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "    return None\n",
    "\n",
    "\n",
    "class RocksData(Dataset):\n",
    "    def __init__(self, df, root_dir):\n",
    "        super(RocksData).__init__()\n",
    "        self.df = df\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                              std=[0.229, 0.224, 0.225])\n",
    "        self.root_dir = root_dir\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, ix):\n",
    "        img_path = self.root_dir + \"/\" + self.df.iloc[ix,0]\n",
    "        img = cv2.imread(img_path)/255.\n",
    "        kp = deepcopy(self.df.iloc[ix,1:].tolist())\n",
    "        kp_x = (np.array(kp[0::2])/img.shape[1]).tolist()\n",
    "        kp_y = (np.array(kp[1::2])/img.shape[0]).tolist()\n",
    "        kp2 = kp_x + kp_y\n",
    "        kp2 = torch.tensor(kp2) \n",
    "        img = self.preprocess_input(img)\n",
    "        return img, kp2\n",
    "    def preprocess_input(self, img):\n",
    "        img = cv2.resize(img, (224,224))\n",
    "        img = torch.tensor(img).permute(2,0,1)\n",
    "        img = self.normalize(img).float()\n",
    "        return img.to(device)\n",
    "    def load_img(self, ix):\n",
    "        img_path = self.root_dir + \"/\" + self.df.iloc[ix,0]        \n",
    "        img = cv2.imread(img_path)\n",
    "        img =cv2.cvtColor(img, cv2.COLOR_BGR2RGB)/255.\n",
    "        img = cv2.resize(img, (224,224))\n",
    "        return img"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "data_transforms = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "train, test = train_test_split(df, test_size=90, random_state=0)\n",
    "train_dataset = RocksData(train.reset_index(drop=True), img_dir)\n",
    "test_dataset = RocksData(test.reset_index(drop=True), img_dir)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size_im)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size_im)\n",
    "\n",
    "dataloaders_dict = {\"train\":train_loader,\"val\":test_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create intermediate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO change later from resnet18 to resnet50\n",
    "model_im = models.resnet50(pretrained=True)\n",
    "set_parameter_requires_grad(model_im, feature_extract_im)\n",
    "num_ftrs = model_im.fc.in_features\n",
    "model_im.fc = nn.Linear(num_ftrs, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "loglr = -2.2200654426745987\n",
    "lr_im = 10 ** loglr\n",
    "\n",
    "# Send the model to GPU\n",
    "model_im = model_im.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are \n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update_im = model_im.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract_im:\n",
    "    params_to_update_im = []\n",
    "    for name,param in model_im.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update_im.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_im.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_im = optim.Adam(params_to_update_im, lr = lr_im) # for the intermediate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Training and Validation Step\n",
    "\n",
    "**Intermediate model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "train Loss:  10.0941 Acc: -12277.0023\n",
      "val Loss:  6.1467 Acc: -7125.0966\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "train Loss:  11.7208 Acc: -13680.0149\n",
      "val Loss:  2.5017 Acc: -2973.2714\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "train Loss:  2.5713 Acc: -2885.9245\n",
      "val Loss:  7.6893 Acc: -9090.7989\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "train Loss:  5.9648 Acc: -7051.7423\n",
      "val Loss:  0.1820 Acc: -207.3851\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "train Loss:  1.6447 Acc: -1829.0315\n",
      "val Loss:  4.4756 Acc: -5251.6966\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "train Loss:  2.8071 Acc: -3333.5759\n",
      "val Loss:  0.1290 Acc: -150.2559\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "train Loss:  1.1179 Acc: -1254.0694\n",
      "val Loss:  2.3464 Acc: -2783.8831\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "train Loss:  1.3437 Acc: -1599.1125\n",
      "val Loss:  0.1967 Acc: -231.9169\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "train Loss:  0.7838 Acc: -888.6938\n",
      "val Loss:  1.1737 Acc: -1363.7405\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "train Loss:  0.5998 Acc: -712.7728\n",
      "val Loss:  0.2586 Acc: -323.1091\n",
      "\n",
      "Training complete in 6m 35s\n",
      "Best val Acc: -150.255894\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "\n",
    "loss_name = \"L2\"\n",
    "\n",
    "if loss_name == \"L1\":\n",
    "    criterion = torch.nn.L1Loss()\n",
    "elif loss_name == \"L2\":\n",
    "    criterion = torch.nn.MSELoss()\n",
    "elif loss_name == \"smooth_L1\":\n",
    "    criterion = torch.nn.SmoothL1Loss()\n",
    "elif loss_name == \"huber\":\n",
    "    criterion = torch.nn.HuberLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_im, dataloaders_dict, criterion, optimizer_im, num_epochs = num_epochs_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6066e5c250>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create finetuned model\n",
    "\n",
    "### Set all parameters to trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_parameter_requires_grad(model_ft, feature_extract_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### different batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size_ft)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size_ft)\n",
    "\n",
    "dataloaders_dict = {\"train\":train_loader,\"val\":test_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lr_ft = 0.0001\n",
    "\n",
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are \n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update_ft = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract_ft:\n",
    "    params_to_update_ft = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update_ft.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update_ft, lr = lr_ft, momentum = 0.9) # for the finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Training and Validation Step\n",
    "\n",
    "**Finetuned model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Setup the loss fxn\n",
    "\n",
    "loss_name = \"L2\"\n",
    "\n",
    "if loss_name == \"L1\":\n",
    "    criterion = torch.nn.L1Loss()\n",
    "elif loss_name == \"L2\":\n",
    "    criterion = torch.nn.MSELoss()\n",
    "elif loss_name == \"smooth_L1\":\n",
    "    criterion = torch.nn.SmoothL1Loss()\n",
    "elif loss_name == \"huber\":\n",
    "    criterion = torch.nn.HuberLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs = num_epochs_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"CNN_checkpoints/state_dict_model_ft.pt\"\n",
    "torch.save(model_ft.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet18()\n",
    "set_parameter_requires_grad(model_ft, feature_extract_ft)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "model_ft.load_state_dict(torch.load(PATH))\n",
    "\n",
    "model_ft.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
