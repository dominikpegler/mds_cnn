{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit CNN in PyTorch\n",
    "===\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import cv2\n",
    "from skimage import io, transform\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# number of models\n",
    "n_ensemble = 2\n",
    "\n",
    "# Number of dimensions in the dataset\n",
    "n_dim = 8\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size_im = 90\n",
    "batch_size_ft = 30\n",
    "\n",
    "# Number of epochs to train for \n",
    "num_epochs_im = 15\n",
    "num_epochs_ft = 15\n",
    "\n",
    "# where would we use these in pytorch? in keras they are used to create layers for the intermediate model\n",
    "dropout = 0.5   \n",
    "n_dense = 256\n",
    "n_layers = 2\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model, \n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract_im = True\n",
    "feature_extract_ft = False\n",
    "\n",
    "input_size = 224\n",
    "\n",
    "loglr = -2.2200654426745987\n",
    "lr_im = 1.16 * 10 ** loglr\n",
    "lr_ft = 0.000666\n",
    "\n",
    "IMG_360 = \"../sanders_2018/360 Rocks\"\n",
    "IMG_120 = '../sanders_2018/120 Rocks'\n",
    "MDS_360 = \"../finetuning_torchvision_data/mds_360.csv\"\n",
    "PATH_IM = 'CNN_checkpoints/state_dict_intermediate_model.pt'\n",
    "PATH_FT = 'CNN_checkpoints/state_dict_finetuned_model.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=14, is_inception=False):\n",
    "    \"\"\"\n",
    "    handles the training and validation of a given model. At the end of\n",
    "    training returns the best performing model. After each epoch, the training and validation\n",
    "    accuracies are printed\n",
    "    \"\"\"\n",
    "    \n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    lrs = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_r2 = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    score = r2_score(labels.detach().numpy(), outputs.detach().numpy())\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        lr = optimizer.param_groups[0][\"lr\"]\n",
    "                        lrs.append(lr)\n",
    "\n",
    "                # statistics \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_r2 += score.item() * inputs.size(0)\n",
    "                \n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset) \n",
    "            epoch_acc = running_r2 / len(dataloaders[phase].dataset) \n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss: .4f} Acc: {epoch_acc: .4f} lr: {lr: .4e}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and best_acc == None:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val' and best_acc < epoch_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "        \n",
    "        print() # empty line between epochs\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history, lrs\n",
    "\n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    \"\"\"\n",
    "    This helper function sets the ``.requires_grad`` attribute of the\n",
    "    parameters in the model to False when we are feature extracting.\n",
    "    \"\"\"\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    else:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = True\n",
    "    return None\n",
    "\n",
    "\n",
    "class RocksData(datasets.VisionDataset):\n",
    "    def __init__(self, df, root_dir):\n",
    "        super(RocksData).__init__()\n",
    "        self.df = df\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                             std=[0.229, 0.224, 0.225])\n",
    "        self.root_dir = root_dir\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, ix):\n",
    "        img_path = self.root_dir + \"/\" + self.df.iloc[ix,0]\n",
    "        img = cv2.imread(img_path)/255.\n",
    "        label = deepcopy(self.df.iloc[ix,1:].tolist())\n",
    "        label = torch.tensor(label).float()\n",
    "        img = self.preprocess_input(img)\n",
    "        return img, label\n",
    "    def preprocess_input(self, img):\n",
    "        img = cv2.resize(img, (224,224))\n",
    "        img = torch.tensor(img).permute(2,0,1)\n",
    "        img = self.normalize(img).float()\n",
    "        return img.to(device)    \n",
    "\n",
    "def get_criterion(loss_name):\n",
    "    \"\"\"\n",
    "    Returns the optimizer\n",
    "    \"\"\"\n",
    "    if loss_name == \"L1\":\n",
    "        return torch.nn.L1Loss()\n",
    "    elif loss_name == \"L2\":\n",
    "        return torch.nn.MSELoss()\n",
    "    elif loss_name == \"smooth_L1\":\n",
    "        return torch.nn.SmoothL1Loss()\n",
    "    elif loss_name == \"huber\":\n",
    "        return torch.nn.HuberLoss()\n",
    "    else:\n",
    "        raise Exception(\"No valid loss_name entered!\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "data_transforms = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(MDS_360)\n",
    "\n",
    "train, test = train_test_split(df, test_size=90, random_state=0)\n",
    "train_dataset = RocksData(train.reset_index(drop=True), IMG_360)\n",
    "test_dataset = RocksData(test.reset_index(drop=True), IMG_360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define final layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the final layers look like in Keras:\n",
    "\n",
    "```\n",
    "__________________________________________________________________________________________________\n",
    " Layer (type)                   Output Shape         Param #     Connected to                     \n",
    "==================================================================================================\n",
    "\n",
    "avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
    " 2D)                                                                                              \n",
    "                                                                                                  \n",
    " dropout (Dropout)              (None, 2048)         0           ['avg_pool[0][0]']               \n",
    "                                                                                                  \n",
    " dense (Dense)                  (None, 256)          524544      ['dropout[0][0]']                \n",
    "                                                                                                  \n",
    " batch_normalization (BatchNorm  (None, 256)         1024        ['dense[0][0]']                  \n",
    " alization)                                                                                       \n",
    "                                                                                                  \n",
    " dropout_1 (Dropout)            (None, 256)          0           ['batch_normalization[0][0]']    \n",
    "                                                                                                  \n",
    " dense_1 (Dense)                (None, 256)          65792       ['dropout_1[0][0]']              \n",
    "                                                                                                  \n",
    " batch_normalization_1 (BatchNo  (None, 256)         1024        ['dense_1[0][0]']                \n",
    " rmalization)                                                                                     \n",
    "                                                                                                  \n",
    " dropout_2 (Dropout)            (None, 256)          0           ['batch_normalization_1[0][0]']  \n",
    "                                                                                                  \n",
    " dense_2 (Dense)                (None, 8)            2056        ['dropout_2[0][0]']       \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_layers(dropout, num_ftrs, n_dim, n_layers):\n",
    "    \"\"\"\n",
    "    Returns the output layers.\n",
    "    \"\"\"\n",
    "   \n",
    "    output = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(num_ftrs, n_dense), # dense in keras\n",
    "            nn.ReLU(inplace=True), # dense\n",
    "            nn.BatchNorm1d(n_dense),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(n_dense, n_dense), # dense\n",
    "            nn.ReLU(inplace=True), # dense\n",
    "            nn.BatchNorm1d(n_dense),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(n_dense, n_dim) # dense\n",
    "        )\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Train intermediate model only"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Intermediate model\n",
    "model = models.resnet50(pretrained=True)\n",
    "set_parameter_requires_grad(model, feature_extract_im)\n",
    "num_ftrs = model.fc.in_features\n",
    "new_layers = get_output_layers(dropout, num_ftrs, n_dim, n_layers)\n",
    "model.fc = new_layers # last fully connected layer\n",
    "    \n",
    "# Send the model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# create datalaoders with specific batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size_im)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size_im)\n",
    "dataloaders_dict = {\"train\":train_loader,\"val\":test_loader}\n",
    "\n",
    "# Create Optimizer and define params to update\n",
    "params_to_update = model.parameters()\n",
    "#print('Params to learn for intermediate training:')\n",
    "if feature_extract_im:\n",
    "    params_to_update = []\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            #print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            #print(\"\\t\",name)\n",
    "\n",
    "# Instantiate optimizer for intermediate model\n",
    "optimizer = optim.Adam(params_to_update, lr = lr_im)\n",
    "\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = get_criterion('L2')\n",
    "\n",
    "# Initial training and evaluate\n",
    "model, hist, lrs = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs = num_epochs_im)\n",
    "\n",
    "# Plot learning curve\n",
    "plt.plot(hist)\n",
    "plt.title('Intermediate model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict()\n",
    "            }, PATH_IM)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Train finetuned model only"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Load intermediate model for finetuning\n",
    "model = models.resnet50(pretrained=True)\n",
    "set_parameter_requires_grad(model, feature_extract_ft)\n",
    "num_ftrs = model.fc.in_features\n",
    "new_layers = get_output_layers(dropout, num_ftrs, n_dim, n_layers)\n",
    "model.fc = new_layers # last fully connected layer\n",
    "    \n",
    "# OPTIONAL: Load pre-trained state\n",
    "checkpoint = torch.load(PATH_IM)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Send the model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# create datalaoders with specific batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size_ft)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size_ft)\n",
    "dataloaders_dict = {\"train\":train_loader,\"val\":test_loader}\n",
    "\n",
    "# Create Optimizer and define params to update\n",
    "params_to_update = model.parameters()\n",
    "#print('Params to learn for finetuning:')\n",
    "if feature_extract_ft:\n",
    "    params_to_update = []\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            #print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            #print(\"\\t\",name)\n",
    "            ...\n",
    "\n",
    "# Instantiate optimizer for finetuning\n",
    "optimizer = optim.SGD(params_to_update, lr = lr_ft, momentum = 0.9)\n",
    "\n",
    "# Setup the loss fxn\n",
    "criterion = get_criterion(\"L2\")\n",
    "\n",
    "# Train and evaluate fine tuned model\n",
    "model, hist, lrs = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs = num_epochs_ft)\n",
    "\n",
    "# Plot learning curve\n",
    "plt.plot(hist)\n",
    "plt.title('Finetuned model')\n",
    "plt.show()\n",
    "\n",
    "# Save finetuned model\n",
    "torch.save(model.state_dict(), PATH_FT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for e in range(1, n_ensemble + 1):\n",
    "       \n",
    "    # Intermediate model\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    set_parameter_requires_grad(model, feature_extract_im)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    new_layers = get_output_layers(dropout, num_ftrs, n_dim, n_layers)\n",
    "    model.fc = new_layers # last fully connected layer\n",
    "    \n",
    "    # Send the model to GPU\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # create datalaoders with specific batch size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size_im)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size_im)\n",
    "    dataloaders_dict = {\"train\":train_loader,\"val\":test_loader}\n",
    "    \n",
    "    # Create Optimizer and define params to update\n",
    "    params_to_update = model.parameters()\n",
    "    if feature_extract_im:\n",
    "        params_to_update = []\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "                #print(\"\\t\",name)\n",
    "\n",
    "    else:\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                #print(\"\\t\",name)\n",
    "                ...\n",
    "\n",
    "\n",
    "    # Instantiate optimizer for intermediate model\n",
    "    optimizer = optim.Adam(params_to_update, lr = lr_im)\n",
    "    \n",
    "    # Setup the loss fxn\n",
    "    criterion = get_criterion('L2')\n",
    "    \n",
    "    # Initial training and evaluate\n",
    "    model, hist, lrs = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs = num_epochs_im)\n",
    "    \n",
    "    # Plot learning curve\n",
    "    plt.plot(hist)\n",
    "    plt.title('Intermediate model')\n",
    "    plt.show()\n",
    "    \n",
    "    # Save intermediate model\n",
    "    torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, PATH_IM)\n",
    "\n",
    "    # fine tuning\n",
    "    \n",
    "    # create datalaoders with specific batch size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size_ft)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size_ft)\n",
    "    dataloaders_dict = {\"train\":train_loader,\"val\":test_loader}\n",
    "            \n",
    "    # Create Optimizer and define params to update\n",
    "    params_to_update = model.parameters()\n",
    "    if feature_extract_ft:\n",
    "        params_to_update = []\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "                #print(\"\\t\",name)\n",
    "    else:\n",
    "        for name,param in model.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                #print(\"\\t\",name)\n",
    "                ...\n",
    "\n",
    "    # Instantiate optimizer for finetuning\n",
    "    optimizer = optim.SGD(params_to_update, lr = lr_ft, momentum = 0.9)\n",
    "    \n",
    "    # Setup the loss fxn\n",
    "    criterion = get_criterion(\"L2\")\n",
    "\n",
    "    # Train and evaluate fine tuned model\n",
    "    model, hist, lrs = train_model(model, dataloaders_dict, criterion, optimizer, num_epochs = num_epochs_ft)\n",
    "    \n",
    "    # Plot learning curve\n",
    "    plt.plot(hist)\n",
    "    plt.title(f'Ensemble model {e}')\n",
    "    plt.show()\n",
    "    \n",
    "    # Save intermediate model\n",
    "    PATH_EN = f'CNN_checkpoints/state_dict_ensemble_model_{e}.pt'\n",
    "    torch.save(model.state_dict(), PATH_EN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Load pre-trained state\n",
    "# model = ...\n",
    "# checkpoint = torch.load(PATH_IM)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate and predict functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, testloader, criterion):\n",
    "    \"\"\"Takes test dataloader and returns loss and score\"\"\"\n",
    "    model.eval()\n",
    "    print('Validation')\n",
    "    valid_running_loss = 0.0\n",
    "    valid_running_score = 0\n",
    "    with torch.no_grad():        \n",
    "        for i, data in enumerate(testloader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # forward pass\n",
    "            outputs = model(inputs)\n",
    "            # calculate the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_running_loss += loss.item()\n",
    "            # calculate the accuracy\n",
    "            score = r2_score(labels, outputs)\n",
    "            valid_running_score += score\n",
    "        \n",
    "    # loss and accuracy for the complete epoch\n",
    "    epoch_loss = valid_running_loss / (i+1)\n",
    "    epoch_acc = valid_running_score / (i+1)\n",
    "\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def predict(model, img_path):\n",
    "        \"\"\"Takes model and picture(s) and predicts the MDS coordinates\"\"\"\n",
    "        model.eval()\n",
    "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                             std=[0.229, 0.224, 0.225])\n",
    "        img = cv2.imread(img_path)/255.\n",
    "        img = cv2.resize(img, (224,224))\n",
    "        img = torch.tensor(img).permute(2,0,1)\n",
    "        img = normalize(img).float().unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            output = model(img.to(device))\n",
    "            \n",
    "        return output.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting 120 Rocks set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_120_files = glob(IMG_120 + '/*')\n",
    "\n",
    "rocks_120_prediction = []\n",
    "\n",
    "for img_file in img_120_files:\n",
    "    rocks_120_prediction.append(predict(model, img_file))\n",
    "\n",
    "rocks_120_prediction = np.array(rocks_120_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save predictions to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_pred_file = \"CNN Predictions/MDS Dimensions/cnn_torch_predicted_mds_120.txt\"\n",
    "\n",
    "np.savetxt(cnn_pred_file, rocks_120_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
